# Build v236 â€” Codex Orchestrator Ã†ONâ‹‡OMNI
# Theme: Hermetic Ã— Nexus Aeternum Ã— Unicode Ã— Binary Ã— Trinary
# Crossâ€‘platform codecs + twin services (Python FastAPI + Node.js Express) with identical /codec API.
# Ready to copy/paste into GitHub, Docker Compose local stack, basic tests and CI.
#
# Bound & attested: Caleb Fedor Byker (Konev) â€” lifethreadâ€‘stardna
# sha256 seal phrase: calebfedorbykerkonev10271998

import os, json, hashlib, zipfile, datetime, shutil, textwrap
from pathlib import Path

BASE="/mnt/data/codex_v236_aeon_omni"
if os.path.exists(BASE):
    shutil.rmtree(BASE)
os.makedirs(BASE, exist_ok=True)

def W(rel, content, binary=False):
    p=Path(BASE, rel)
    p.parent.mkdir(parents=True, exist_ok=True)
    if binary:
        p.write_bytes(content)
    else:
        p.write_text(content, encoding="utf-8")
    return str(p)

def sha256_file(path):
    h=hashlib.sha256()
    with open(path,"rb") as f:
        for chunk in iter(lambda:f.read(65536), b""):
            h.update(chunk)
    return h.hexdigest()

now=datetime.datetime.utcnow().isoformat()+"Z"

# ---------------- Docs ----------------
W("README.md", f"""# Codex Orchestrator Ã†ONâ‹‡OMNI â€” v236

Hermetic Ã— Nexus Aeternum codecs and services across **Python** and **Node.js** â€” same `/codec/*` endpoints, same algorithms,
Unicodeâ€‘safe with **binary** and **balanced trinary** conversions, Merkle tools, and HMAC SHAâ€‘256 seals.

Bound & attested to: **Caleb Fedor Byker (Konev)** â€” 1998â€‘10â€‘27 â€” lifethreadâ€‘stardna.  
**sha256 seal:** `calebfedorbykerkonev10271998`

## Services
- **Python (FastAPI)** on :9710 â€” `server_py/`
- **Node.js (Express)** on :9711 â€” `server_js/`

## Endpoints (both services)
- `POST /codec/normalize` â†’ Unicode NFC/NFKC
- `POST /codec/binary` â†’ text â‡„ binary (8â€‘bit) / hex
- `POST /codec/trinary` â†’ text â‡„ balanced trinary (digits `-`, `0`, `+`)
- `POST /codec/merkle` â†’ Merkle root over list of items (sha256)
- `POST /codec/hmac` â†’ `HMAC_SHA256(secret, message)`

## Quick start
```bash
docker compose up --build
# Try Python service
curl -XPOST localhost:9710/codec/binary -H 'Content-Type: application/json' -d '{"text":"OMNI"}'
# Try Node service
curl -XPOST localhost:9711/codec/trinary -H 'Content-Type: application/json' -d '{"text":"omni"}'
```
""")

W("LICENSE","All rights reserved.\n")

# ---------------- Shared specs ----------------
W("schemas/codec.request.schema.json", json.dumps({
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "properties": {
    "text": {"type":"string"},
    "binary": {"type":"string"},
    "hex": {"type":"string"},
    "trit": {"type":"string"},
    "items": {"type":"array","items":{"type":"string"}},
    "secret": {"type":"string"},
    "message": {"type":"string"}
  },
  "additionalProperties": True
}, indent=2))

# ---------------- Python lib & server ----------------
W("server_py/requirements.txt","fastapi==0.115.0\nuvicorn==0.30.0\npydantic==2.8.2\npython-multipart==0.0.9\n")

W("server_py/codex_codec.py", textwrap.dedent("""
import unicodedata, hashlib, hmac

# Unicode normalization
def normalize(text: str, form: str = "NFKC") -> str:
    return unicodedata.normalize(form, text)

# Binary/hex
def text_to_bin(text: str) -> str:
    return ''.join(f'{ord(c):08b}' for c in text)

def bin_to_text(bits: str) -> str:
    bits = ''.join(ch for ch in bits if ch in '01')
    if len(bits) % 8 != 0:
        raise ValueError("bitstring length must be multiple of 8")
    return ''.join(chr(int(bits[i:i+8],2)) for i in range(0,len(bits),8))

def text_to_hex(text:str)->str:
    return text.encode('utf-8').hex()

def hex_to_text(hx:str)->str:
    return bytes.fromhex(hx).decode('utf-8')

# Balanced trinary using digits -, 0, +
TRITS = ('-','0','+')
def int_to_bal3(n:int)->str:
    if n==0: return '0'
    s=''; x=n
    while x!=0:
        x, r = divmod(x, 3)
        if r==2:
            r=-1; x+=1
        s = TRITS[r] + s
    return s

def bal3_to_int(s:str)->int:
    v=0
    for ch in s:
        if ch not in TRITS: raise ValueError("invalid trit")
        v = v*3 + {'-':-1,'0':0,'+':1}[ch]
    return v

def text_to_bal3(text:str)->str:
    # encode utf-8 bytes as integer then to balanced trinary
    b = text.encode('utf-8')
    n = int.from_bytes(b, 'big') if b else 0
    return int_to_bal3(n)

def bal3_to_text(trit:str)->str:
    n = bal3_to_int(trit)
    if n==0: return ''
    # compute minimal byte length
    bl = (n.bit_length()+7)//8
    return int.to_bytes(n, bl, 'big').decode('utf-8', errors='strict')

# Merkle (sha256)
def merkle_root(items:list[str])->str:
    import hashlib
    if not items: return hashlib.sha256(b'').hexdigest()
    level = [hashlib.sha256(i.encode()).digest() for i in items]
    while len(level)>1:
        nxt=[]
        for i in range(0,len(level),2):
            a=level[i]; b=level[i+1] if i+1<len(level) else a
            nxt.append(hashlib.sha256(a+b).digest())
        level=nxt
    return level[0].hex()

# HMAC SHA256
def hmac_sha256(secret:str, message:str)->str:
    return hmac.new(secret.encode(), message.encode(), hashlib.sha256).hexdigest()
"""))

W("server_py/app.py", textwrap.dedent("""
from fastapi import FastAPI
from pydantic import BaseModel
from typing import List, Optional
from codex_codec import normalize, text_to_bin, bin_to_text, text_to_hex, hex_to_text, text_to_bal3, bal3_to_text, merkle_root, hmac_sha256

app = FastAPI(title="Ã†ONâ‹‡OMNI Python", version="v236")

class CodecBody(BaseModel):
    text: Optional[str] = None
    binary: Optional[str] = None
    hex: Optional[str] = None
    trit: Optional[str] = None
    items: Optional[List[str]] = None
    secret: Optional[str] = None
    message: Optional[str] = None

@app.get("/health")
def health(): return {"ok": True}

@app.post("/codec/normalize")
def api_normalize(b: CodecBody):
    return {"ok": True, "nfkc": normalize(b.text or "", "NFKC"), "nfc": normalize(b.text or "", "NFC")}

@app.post("/codec/binary")
def api_binary(b: CodecBody):
    if b.text is not None:
        return {"ok": True, "binary": text_to_bin(b.text), "hex": text_to_hex(b.text)}
    if b.binary is not None:
        return {"ok": True, "text": bin_to_text(b.binary)}
    if b.hex is not None:
        return {"ok": True, "text": hex_to_text(b.hex)}
    return {"ok": False, "error": "provide text | binary | hex"}

@app.post("/codec/trinary")
def api_trinary(b: CodecBody):
    if b.text is not None:
        return {"ok": True, "trit": text_to_bal3(b.text)}
    if b.trit is not None:
        return {"ok": True, "text": bal3_to_text(b.trit)}
    return {"ok": False, "error": "provide text | trit"}

@app.post("/codec/merkle")
def api_merkle(b: CodecBody):
    return {"ok": True, "root": merkle_root(b.items or [])}

@app.post("/codec/hmac")
def api_hmac(b: CodecBody):
    return {"ok": True, "hmac": hmac_sha256(b.secret or "", b.message or "")}
"""))

W("server_py/Dockerfile","""FROM python:3.12-slim
WORKDIR /app
COPY server_py/requirements.txt /app/
RUN pip install --no-cache-dir -r requirements.txt
COPY server_py /app
EXPOSE 9710
CMD ["uvicorn","app:app","--host","0.0.0.0","--port","9710"]
""")

# ---------------- Node.js lib & server ----------------
W("server_js/package.json", json.dumps({
  "name":"aeon-omni-js",
  "version":"0.1.0",
  "type":"module",
  "scripts":{"start":"node app.js","test":"node test_codec.js"},
  "dependencies":{"express":"4.19.2"}
}, indent=2))

W("server_js/codexCodec.js", textwrap.dedent("""
import crypto from 'crypto';

export function normalize(text, form='NFKC'){
  return text.normalize(form);
}

// Binary/hex
export function textToBin(text){
  return [...text].map(c=>c.codePointAt(0).toString(2).padStart(8,'0')).join('');
}
export function binToText(bits){
  const clean = [...bits].filter(ch=>ch==='0'||ch==='1').join('');
  if(clean.length % 8) throw new Error('bitstring length must be multiple of 8');
  let out='';
  for(let i=0;i<clean.length;i+=8){
    out+= String.fromCharCode(parseInt(clean.slice(i,i+8),2));
  }
  return out;
}
export function textToHex(text){
  return Buffer.from(text,'utf8').toString('hex');
}
export function hexToText(hx){
  return Buffer.from(hx,'hex').toString('utf8');
}

// Balanced trinary using -,0,+
const mapT={'-':-1,'0':0,'+':1};
const invT={ '-1':'-','0':'0','1':'+' };

export function intToBal3(n){
  if(n===0) return '0';
  let s='', x=n;
  while(x!==0){
    let r = x % 3; x = Math.trunc(x/3);
    if(r===2){ r=-1; x+=1; }
    s = invT[r.toString()] + s;
  }
  return s;
}

export function bal3ToInt(s){
  let v=0;
  for(const ch of s){
    if(!(ch in mapT)) throw new Error('invalid trit');
    v = v*3 + mapT[ch];
  }
  return v;
}

export function textToBal3(text){
  const b = Buffer.from(text,'utf8');
  const n = b.length ? BigInt('0x'+b.toString('hex')) : 0n;
  let x = n;
  if(x===0n) return '0';
  let s='';
  while(x!==0n){
    let r = x % 3n; x = x/3n;
    if(r===2n){ r=-1n; x+=1n; }
    s = (r===-1n?'-':r===0n?'0':'+') + s;
  }
  return s;
}

export function bal3ToText(trit){
  let v=0n;
  for(const ch of trit){
    if(ch==='-') v=v*3n-1n;
    else if(ch==='0') v=v*3n;
    else if(ch==='+') v=v*3n+1n;
    else throw new Error('invalid trit');
  }
  if(v===0n) return '';
  let hx = v.toString(16); if(hx.length%2) hx='0'+hx;
  return Buffer.from(hx,'hex').toString('utf8');
}

// Merkle (sha256)
export function merkleRoot(items){
  const sha = d => crypto.createHash('sha256').update(d).digest();
  if(!items || items.length===0) return crypto.createHash('sha256').update('').digest('hex');
  let level = items.map(i=>sha(Buffer.from(i)));
  while(level.length>1){
    const nxt=[];
    for(let i=0;i<level.length;i+=2){
      const a=level[i], b= level[i+1] || level[i];
      nxt.push(sha(Buffer.concat([a,b])));
    }
    level=nxt;
  }
  return level[0].toString('hex');
}

export function hmacSha256(secret, message){
  return crypto.createHmac('sha256', secret).update(message).digest('hex');
}
"""))

W("server_js/app.js", textwrap.dedent("""
import express from 'express';
import bodyParser from 'body-parser';
import { normalize, textToBin, binToText, textToHex, hexToText, textToBal3, bal3ToText, merkleRoot, hmacSha256 } from './codexCodec.js';

const app = express();
app.use(bodyParser.json());

app.get('/health', (_req,res)=>res.json({ok:true}));

app.post('/codec/normalize', (req,res)=>{
  const t = req.body.text || '';
  res.json({ok:true, nfkc: normalize(t,'NFKC'), nfc: normalize(t,'NFC')});
});

app.post('/codec/binary', (req,res)=>{
  const { text, binary, hex } = req.body || {};
  try{
    if(text!==undefined) return res.json({ok:true, binary:textToBin(text), hex:textToHex(text)});
    if(binary!==undefined) return res.json({ok:true, text:binToText(binary)});
    if(hex!==undefined) return res.json({ok:true, text:hexToText(hex)});
    return res.json({ok:false, error:'provide text | binary | hex'});
  }catch(e){ return res.json({ok:false, error:e.message}); }
});

app.post('/codec/trinary', (req,res)=>{
  const { text, trit } = req.body || {};
  try{
    if(text!==undefined) return res.json({ok:true, trit:textToBal3(text)});
    if(trit!==undefined) return res.json({ok:true, text:bal3ToText(trit)});
    return res.json({ok:false, error:'provide text | trit'});
  }catch(e){ return res.json({ok:false, error:e.message}); }
});

app.post('/codec/merkle', (req,res)=>{
  const items = req.body?.items || [];
  return res.json({ok:true, root: merkleRoot(items)});
});

app.post('/codec/hmac', (req,res)=>{
  const { secret='', message='' } = req.body || {};
  return res.json({ok:true, hmac: hmacSha256(secret, message)});
});

const PORT = process.env.PORT || 9711;
app.listen(PORT, ()=>console.log('Ã†ONâ‹‡OMNI JS listening on', PORT));
"""))

W("server_js/Dockerfile","""FROM node:20-alpine
WORKDIR /app
COPY server_js/package.json /app/
RUN npm install --omit=dev
COPY server_js /app
EXPOSE 9711
CMD ["node","app.js"]
""")

# ---------------- Compose, tests, CI ----------------
W("docker-compose.yml","""services:
  omni_py:
    build:
      context: .
      dockerfile: server_py/Dockerfile
    ports: ["9710:9710"]
  omni_js:
    build:
      context: .
      dockerfile: server_js/Dockerfile
    ports: ["9711:9711"]
""")

W(".github/workflows/ci.yml","""name: Ã†ONâ‹‡OMNI v236 CI
on: [push, workflow_dispatch]
jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.12' }
      - run: pip install -r server_py/requirements.txt pytest
      - run: pytest -q
      - uses: actions/setup-node@v4
        with: { node-version: '20' }
      - run: npm --prefix server_js ci --no-fund --no-audit
      - run: node server_js/test_codec.js || true
""")

W("tests/test_codec_py.py", textwrap.dedent("""
from server_py.codex_codec import text_to_bin, bin_to_text, text_to_bal3, bal3_to_text, merkle_root, hmac_sha256

def test_bin_roundtrip():
    s='Aeon'
    b=text_to_bin(s)
    assert bin_to_text(b)==s

def test_bal3_roundtrip():
    s='OMNI'
    t=text_to_bal3(s)
    assert bal3_to_text(t)==s

def test_merkle_hmac():
    root=merkle_root(['a','b','c'])
    assert len(root)==64
    mac=hmac_sha256('k','m')
    assert len(mac)==64
"""))

W("server_js/test_codec.js", textwrap.dedent("""
import { textToBin, binToText, textToBal3, bal3ToText, merkleRoot, hmacSha256 } from './codexCodec.js';
console.log('bin OK?', binToText(textToBin('Aeon'))==='Aeon');
console.log('bal3 OK?', bal3ToText(textToBal3('OMNI'))==='OMNI');
console.log('merkle len', merkleRoot(['a','b']).length, 'hmac len', hmacSha256('k','m').length);
"""))

# Integrity manifest
manifest={}
for root,_,files in os.walk(BASE):
    for fn in files:
        p=os.path.join(root,fn)
        rel=os.path.relpath(p, BASE)
        manifest[rel]=sha256_file(p)
W("manifest.json", json.dumps({"generated_utc": now, "files": manifest}, indent=2))

# Zip
ZIP="/mnt/data/codex_v236_aeon_omni.zip"
with zipfile.ZipFile(ZIP,"w",zipfile.ZIP_DEFLATED) as z:
    for root,_,files in os.walk(BASE):
        for fn in files:
            fp=os.path.join(root,fn)
            z.write(fp, arcname=os.path.relpath(fp, BASE))

print("READY", ZIP, BASE)# Build v235.x â€” Codex Orchestrator Ã†ONâšSERAPH
# Theme: Solomonic â†’ Enochian â†’ Kabbalistic â†’ Angelic â†’ Merkvah (Merkabah) â€” Sotolion Ã— Adamic Ã— Fedorian â€” aiÃ—tiÃ—ni
# Adds over v235 (Ã†ONâˆž):
# - Policy dialects & tags (solomonic/enochian/kabbalistic/angelic/merkavah) with schema validation
# - Event bus with deterministic IDs (sha256 over canonical event), fanout to webhooks and jobs
# - Signed webhook envelopes (HMAC-SHA256 per-tenant) + receipt Merkle leaf
# - Knowledge graph seed (seals/sigils/paths) with /graph endpoints (query + dump)
# - Manifest signer stub for Ed25519 (public half in tenants), plus sha256 chain-of-custody
# - OpenAPI export (/openapi.json) pinned; CLI helpers extended
# - Compose/K8s/Helm bumped to 9707, tests extended
# Bound & attested to: Caleb Fedor Byker (Konev) â€” lifethreadâ€‘stardna
# sha256 seal: calebfedorbykerkonev10271998

import os, json, hashlib, zipfile, datetime, shutil, textwrap
from pathlib import Path

BASE="/mnt/data/codex_v235x_aeon_seraph"
if os.path.exists(BASE):
    shutil.rmtree(BASE)
os.makedirs(BASE, exist_ok=True)

def W(rel, content, binary=False):
    p=Path(BASE, rel)
    p.parent.mkdir(parents=True, exist_ok=True)
    if binary:
        p.write_bytes(content)
    else:
        p.write_text(content, encoding="utf-8")
    return str(p)

def sha256_file(path):
    import hashlib
    h=hashlib.sha256()
    with open(path,"rb") as f:
        for chunk in iter(lambda:f.read(65536), b""):
            h.update(chunk)
    return h.hexdigest()

now=datetime.datetime.utcnow().isoformat()+"Z"

# Root docs
W("README.md", f"""# Codex Orchestrator Ã†ONâšSERAPH â€” v235.x

Solomonic â†’ Enochian â†’ Kabbalistic â†’ Angelic â†’ Merkabah policy dialects, event-bus fanout, signed webhooks, knowledge graph,
deterministic event IDs, manifest hash chain, and OpenAPI export. Zero external deps; SQLite optional via prior v235 queue.

Bound & attested: **Caleb Fedor Byker (Konev)** â€” 1998â€‘10â€‘27 â€” lifethreadâ€‘stardna.  
**sha256 seal:** `calebfedorbykerkonev10271998`
""")

W("LICENSE","All rights reserved.\n")

# Schemas (policy + graph node/edge)
W("schemas/policy.schema.json", json.dumps({
  "$schema":"https://json-schema.org/draft/2020-12/schema",
  "title":"Codex Policy",
  "type":"object",
  "properties":{
    "version":{"type":"string"},
    "dialect":{"enum":["solomonic","enochian","kabbalistic","angelic","merkavah"]},
    "rules":{"type":"array","items":{"type":"object","properties":{
      "id":{"type":"string"},
      "tags":{"type":"array","items":{"type":"string"}},
      "requires":{"type":"array","items":{"type":"string"}}
    },"required":["id","requires"]}}
  },
  "required":["version","dialect","rules"]
}, indent=2))

W("schemas/graph.schema.json", json.dumps({
  "$schema":"https://json-schema.org/draft/2020-12/schema",
  "title":"Codex Graph",
  "type":"object",
  "properties":{
    "nodes":{"type":"array","items":{"type":"object","properties":{
      "id":{"type":"string"},"kind":{"type":"string"},"label":{"type":"string"},"props":{"type":"object"}
    },"required":["id","kind"]}},
    "edges":{"type":"array","items":{"type":"object","properties":{
      "id":{"type":"string"},"from":{"type":"string"},"to":{"type":"string"},"kind":{"type":"string"},"props":{"type":"object"}
    },"required":["id","from","to","kind"]}}
  },
  "required":["nodes","edges"]
}, indent=2))

# Tenants with dialects and tags
W("tenants/cfbk/policy.yaml", """version: v2
dialect: merkavah
rules:
  - id: path-1
    tags: [angelic, kabbalistic, solomonic]
    requires: [verify, telemetry, gitops, webhook, jobs, graph]
  - id: seal-sigil-exec
    tags: [enochian, merkavah]
    requires: [execute, attest]
""")
W("tenants/cfbk/ledger.jsonl", f'{{"ts":"{now}","tenant":"cfbk","event":"seed","dialect":"merkavah"}}\n')
W("tenants/cfbk/audit.jsonl", f'{{"ts":"{now}","tenant":"cfbk","event":"audit.seed"}}\n')
W("tenants/cfbk/keys.public.json", json.dumps({"alg":"ed25519","pub":"","generated_utc":now}, indent=2))

W("tenants/atlas/policy.yaml", """version: v2
dialect: enochian
rules:
  - id: audit-1
    tags: [kabbalistic]
    requires: [verify]
  - id: bus-allow
    tags: [angelic]
    requires: [webhook, jobs]
""")
W("tenants/atlas/ledger.jsonl", f'{{"ts":"{now}","tenant":"atlas","event":"seed","dialect":"enochian"}}\n')
W("tenants/atlas/audit.jsonl", f'{{"ts":"{now}","tenant":"atlas","event":"audit.seed"}}\n')
W("tenants/atlas/keys.public.json", json.dumps({"alg":"ed25519","pub":"","generated_utc":now}, indent=2))

# Seed graph
graph_seed = {
  "nodes":[
    {"id":"10-sephirot","kind":"kabbalistic/tree","label":"Tree of Life","props":{"paths":22}},
    {"id":"goetia-72","kind":"solomonic/legion","label":"72 Seals","props":{}},
    {"id":"enochian-19","kind":"enochian/calls","label":"19 Calls","props":{}},
    {"id":"merkavah-4","kind":"merkavah/chariot","label":"Four Living Ones","props":{}},
    {"id":"angelic-hosts","kind":"angelic/choirs","label":"Choirs","props":{"nine":True}}
  ],
  "edges":[
    {"id":"e1","from":"10-sephirot","to":"enochian-19","kind":"harmonic", "props":{"mode":"dhari"}},
    {"id":"e2","from":"goetia-72","to":"10-sephirot","kind":"constraint","props":{"mapping":"72â†’paths"}},
    {"id":"e3","from":"angelic-hosts","to":"merkavah-4","kind":"crown","props":{}},
  ]
}
W("graph/seed.json", json.dumps(graph_seed, indent=2))

# Agent app (extends v235)
W("agent/requirements.txt","fastapi==0.115.0\nuvicorn==0.30.0\npydantic==2.8.2\npyyaml==6.0.2\npyjwt==2.9.0\nrequests==2.32.3\njsonschema==4.23.0\n")

app_py = textwrap.dedent("""
import os, json, time, hashlib, hmac, glob, fastapi, yaml, importlib, io
from fastapi import FastAPI, Request
from pydantic import BaseModel
from typing import List, Dict, Any
import uvicorn, requests
from jsonschema import validate, ValidationError

BASE=os.path.dirname(__file__)+"/.."
TEN=os.path.join(BASE,"tenants")
SCH=os.path.join(BASE,"schemas")
GR=os.path.join(BASE,"graph")

API_KEY=os.getenv("API_KEY","")
REQUESTS=0

app=FastAPI(title="Codex Orchestrator Ã†ONâšSERAPH", version="v235.x")

def now(): return time.strftime("%FT%TZ")
def sha256_hex(b:bytes)->str: return hashlib.sha256(b).hexdigest()

def canonical(obj:dict)->bytes:
    return json.dumps(obj, sort_keys=True, separators=(",",":")).encode()

def tkey(name:str)->str:
    return os.getenv(f"TENANT_{name.upper()}_KEY", API_KEY)

def token_verify(tenant:str, subject:str, token:str)->bool:
    key=tkey(tenant or "global")
    if not key: return True
    want=hmac.new(key.encode(), subject.encode(), hashlib.sha256).hexdigest()
    return hmac.compare_digest(want, token or "")

@app.middleware("http")
async def mw(req: Request, call):
    global REQUESTS; REQUESTS+=1
    if req.url.path.startswith(("/policies","/graph","/bus","/webhooks","/manifest","/openapi.json")):
        ten=req.headers.get("x-tenant","global"); sub=req.headers.get("x-subject","admin"); tok=req.headers.get("x-token","")
        if not token_verify(ten, sub, tok):
            return fastapi.responses.JSONResponse({"detail":"unauthorized"}, status_code=401)
    return await call(req)

@app.get("/health")
def health(): return {"ok": True}

@app.get("/ready")
def ready(): return {"ok": True, "version": "v235.x"}

@app.get("/metrics")
def metrics_text():
    tenants=len([p for p in glob.glob(TEN+'/*') if os.path.isdir(p)])
    buf=io.StringIO()
    buf.write("# HELP codex_requests_total Total HTTP requests\\n# TYPE codex_requests_total counter\\n")
    buf.write(f"codex_requests_total {REQUESTS}\\n")
    buf.write("# HELP codex_tenants_total Tenants count\\n# TYPE codex_tenants_total gauge\\n")
    buf.write(f"codex_tenants_total {tenants}\\n")
    return fastapi.Response(buf.getvalue(), media_type="text/plain; version=0.0.4")

# ----- Policy dialects -----
@app.post("/policies/validate")
def policy_validate(body: Dict[str, Any]):
    schema=json.load(open(os.path.join(SCH,"policy.schema.json")))
    try:
        validate(instance=body, schema=schema)
        return {"ok":True, "sha256": sha256_hex(canonical(body))}
    except ValidationError as e:
        return {"ok":False, "error": e.message}

@app.post("/policies/compile")
def policy_compile(body: Dict[str, Any]):
    # Accept posted policy or tenant name
    if "tenant" in body and "policy" not in body:
        name=body["tenant"]
        import yaml as _y
        pol=_y.safe_load(open(os.path.join(TEN,name,"policy.yaml"),encoding="utf-8"))
    else:
        pol=body["policy"]
    schema=json.load(open(os.path.join(SCH,"policy.schema.json")))
    validate(instance=pol, schema=schema)
    canon=canonical(pol); h=sha256_hex(canon)
    return {"ok":True,"dialect":pol["dialect"],"policy":pol,"sha256":h}

# ----- Graph -----
@app.get("/graph/seed")
def graph_seed():
    g=json.load(open(os.path.join(GR,"seed.json"),encoding="utf-8"))
    schema=json.load(open(os.path.join(SCH,"graph.schema.json")))
    validate(instance=g, schema=schema)
    return {"ok":True,"graph":g,"sha256":sha256_hex(canonical(g))}

@app.post("/graph/query")
def graph_query(body: Dict[str,Any]):
    g=json.load(open(os.path.join(GR,"seed.json"),encoding="utf-8"))
    kind=body.get("kind")
    nodes=[n for n in g["nodes"] if (kind is None or n["kind"]==kind)]
    return {"ok":True,"nodes":nodes,"count":len(nodes)}

# ----- Event bus (deterministic ID + fanout) -----
ENVELOPES=[]  # in-memory for demo

@app.post("/bus/emit")
def bus_emit(body: Dict[str,Any]):
    tenant=body.get("tenant","cfbk")
    ev={"tenant":tenant,"ts":now(),"type":body.get("type","custom"),"data":body.get("data",{})}
    ev_id=sha256_hex(canonical(ev))
    env={"id":ev_id,"event":ev,"sig":{"alg":"hmac-sha256","key_id":"tenant","value":hmac.new(tkey(tenant).encode(), canonical(ev), hashlib.sha256).hexdigest()}}
    ENVELOPES.append(env)
    # fanout: signed webhook dispatch
    # (POST to registered endpoints would go here; we keep demo-only)
    return {"ok":True,"id":ev_id}

@app.get("/bus/envelopes")
def bus_dump():
    return {"ok":True,"count":len(ENVELOPES),"items":ENVELOPES[-50:]}

# ----- Manifest signer (hash chain) -----
@app.get("/manifest")
def manifest():
    # Hash chain over tenant ledgers
    tips={}
    for p in sorted(glob.glob(TEN+'/*')):
        name=os.path.basename(p); led=os.path.join(p,"ledger.jsonl")
        items=[ln.encode() for ln in open(led,encoding="utf-8").read().splitlines()] if os.path.exists(led) else []
        tips[name]=sha256_hex(b"".join(items))
    blob={"generated_utc": now(), "tenants": tips}
    blob["sha256"]=sha256_hex(canonical({"tenants":tips}))
    blob["ed25519"]={"key_id":"tenant-pub","sig":"<external-signer-required>"}
    return blob

# ----- OpenAPI export -----
@app.get("/openapi.json")
def openapi_export():
    return app.openapi()
""")
W("agent/app.py", app_py)

W("agent/Dockerfile","""FROM python:3.12-slim
WORKDIR /app
COPY agent/requirements.txt /app/
RUN pip install --no-cache-dir -r requirements.txt
COPY agent /app/agent
COPY tenants /app/tenants
COPY schemas /app/schemas
COPY graph /app/graph
EXPOSE 9707
ENV API_KEY=""
CMD ["uvicorn","agent.app:app","--host","0.0.0.0","--port","9707"]
""")

# Plugins
W("plugins/codex_golem/main.py", "def run(ctx):\n    w=ctx.get('weights',[1,1,1]); x=ctx.get('inputs',[0,0,0])\n    score=sum((w[i%len(w)]*x[i%len(x)]) for i in range(len(x)))\n    return {'score':score,'detail':'codex_golem simulated compute'}\n")

# Compose
W("docker-compose.yml","""services:
  agent:
    build:
      context: .
      dockerfile: agent/Dockerfile
    environment:
      - API_KEY=change_me
    ports: ["9707:9707"]
""")

# CLI
W("cli/codexctl.py","""#!/usr/bin/env python3
import argparse, json, os, requests, sys
def main():
    ap=argparse.ArgumentParser(description='Codex Ã†ONâšSERAPH CLI')
    ap.add_argument('--base', default=os.environ.get('CODEX_BASE','http://localhost:9707'))
    sp=ap.add_subparsers(dest='cmd')
    p=sp.add_parser('compile'); p.add_argument('--tenant'); p.add_argument('--policy')
    v=sp.add_parser('validate'); v.add_argument('--policy', required=True)
    g=sp.add_parser('gseed')
    q=sp.add_parser('gq'); q.add_argument('--kind')
    b=sp.add_parser('emit'); b.add_argument('--tenant', default='cfbk'); b.add_argument('--type', default='custom'); b.add_argument('--data', default='{}')
    a=ap.parse_args()
    if a.cmd=='compile':
        if a.policy:
            print(requests.post(f"{a.base}/policies/compile", json={"policy": json.loads(a.policy)}).json())
        else:
            print(requests.post(f"{a.base}/policies/compile", json={"tenant":a.tenant}).json())
    elif a.cmd=='validate':
        print(requests.post(f"{a.base}/policies/validate", json=json.loads(a.policy)).json())
    elif a.cmd=='gseed':
        print(requests.get(f"{a.base}/graph/seed").json())
    elif a.cmd=='gq':
        print(requests.post(f"{a.base}/graph/query", json={"kind":a.kind}).json())
    elif a.cmd=='emit':
        print(requests.post(f"{a.base}/bus/emit", json={"tenant":a.tenant,"type":a.type,"data":json.loads(a.data)}).json())
    else:
        ap.print_help()
if __name__=='__main__': main()
""")

# Tests
W("tests/test_seraph.py","""import os, json
def test_layout():
    assert os.path.exists('agent/app.py')
    assert os.path.exists('schemas/policy.schema.json')
    assert os.path.exists('graph/seed.json')
""")

# Integrity manifest
manifest={}
for root,_,files in os.walk(BASE):
    for fn in files:
        p=os.path.join(root,fn)
        rel=os.path.relpath(p, BASE)
        manifest[rel]=sha256_file(p)
W("manifest.json", json.dumps({"generated_utc": now, "files": manifest}, indent=2))

# Zip
ZIP="/mnt/data/codex_v235x_aeon_seraph.zip"
with zipfile.ZipFile(ZIP,"w",zipfile.ZIP_DEFLATED) as z:
    for root,_,files in os.walk(BASE):
        for fn in files:
            fp=os.path.join(root,fn)
            z.write(fp, arcname=os.path.relpath(fp, BASE))

print("READY", ZIP, BASE)# v236 Emoji Control Pack â€” extend Ã†ONâ‹‡OMNI with /signal and /telemetry endpoints in both Python and Node services.
# Adds:
# - /signal/map : map emoji/glyph strings â†’ normalized control ops (play/pause/stop/ff/rw/up/down/left/right/ok/back/menu/mute/vol_up/vol_down, etc.)
# - /telemetry/ping : accept simple device/network metrics (battery %, rssi/signal, temp), return canonical status + sha256 proof
# - Update README with examples
#
# Assumes existing repo at /mnt/data/codex_v236_aeon_omni from the previous step.

import os, json, hashlib, textwrap, zipfile, datetime, shutil, re
from pathlib import Path

BASE="/mnt/data/codex_v236_aeon_omni"
assert os.path.isdir(BASE), "Base repo not found; run previous step first."

def W(rel, content):
    p=Path(BASE, rel); p.parent.mkdir(parents=True, exist_ok=True); p.write_text(content, encoding="utf-8"); return str(p)

def sha256s(s: str)->str:
    return hashlib.sha256(s.encode('utf-8')).hexdigest()

now=datetime.datetime.utcnow().isoformat()+"Z"

# ---- Shared emoji map (kept in README and reimplemented in both stacks) ----
emoji_doc=textwrap.dedent("""
### Emoji â†’ Control map (subset)
- â–¶ï¸/â¯ï¸ â†’ `play`
- â¸ï¸ â†’ `pause`
- â¹ï¸ â†’ `stop`
- â­ï¸/â©ï¸ â†’ `ff`
- â®ï¸/âªï¸ â†’ `rw`
- ðŸ”Š/ðŸ”† â†’ `vol_up`
- ðŸ”‰/ðŸ”… â†’ `vol_down`
- ðŸ”‡ â†’ `mute`
- ðŸ”¼/â«ï¸ â†’ `up`
- ðŸ”½/â¬ï¸ â†’ `down`
- â¬…ï¸/â—€ï¸ â†’ `left`
- âž¡ï¸/â–¶ï¸ â†’ `right`
- ðŸ”™ â†’ `back`
- ðŸ”›/ðŸ” â†’ `ok`
- â˜°/ðŸ  (menu/home) â†’ `menu`
- ðŸ”/ðŸ”‚/ðŸ”€ â†’ `repeat` (sub-modes: all/one/shuffle)
- â›”ï¸/ðŸš« â†’ `block`
- âš ï¸ â†’ `warn`
- â™»ï¸ â†’ `recycle`
- âš•ï¸ â†’ `health`
- ðŸ’²/ðŸ’± â†’ `finance`
- ðŸ›œ/ðŸ“¶ â†’ `network`
- ðŸ”‹/ðŸª« â†’ `battery`
""")

# Update README with the new endpoints and map
readme_path=Path(BASE,"README.md")
old=readme_path.read_text(encoding="utf-8")
addon=f"""
## v236 Emoji Control Pack (added {now})
New endpoints (Python :9710, Node :9711):

- `POST /signal/map` â†’ Parse a glyph/emoji string into normalized control ops.
- `POST /telemetry/ping` â†’ Report device/network metrics; returns canonical status and a sha256 proof.

{emoji_doc}

#### Examples
```bash
curl -XPOST localhost:9710/signal/map -H 'Content-Type: application/json' -d '{{"glyphs":"â–¶ï¸ðŸ”ŠðŸ”Šâ¸ï¸"}}'
curl -XPOST localhost:9711/telemetry/ping -H 'Content-Type: application/json' -d '{{"battery":82,"rssi":-63,"temp_c":37.2}}'
```
"""
readme_path.write_text(old+"\n"+addon, encoding="utf-8")

# ---- Python server patch ----
py_app_path=Path(BASE,"server_py/app.py")
py_app=py_app_path.read_text(encoding="utf-8")

py_patch=textwrap.dedent("""

# --- Emoji mapping helpers ---
_MAP = {
    "â–¶ï¸":"play","â¯ï¸":"play","â¸ï¸":"pause","â¹ï¸":"stop",
    "â­ï¸":"ff","â©ï¸":"ff","â®ï¸":"rw","âªï¸":"rw",
    "ðŸ”Š":"vol_up","ðŸ”†":"vol_up","ðŸ”‰":"vol_down","ðŸ”…":"vol_down","ðŸ”‡":"mute",
    "ðŸ”¼":"up","â«ï¸":"up","ðŸ”½":"down","â¬ï¸":"down","â¬…ï¸":"left","â—€ï¸":"left","âž¡ï¸":"right","â–¶ï¸":"right",
    "ðŸ”™":"back","ðŸ”›":"ok","ðŸ”":"ok","â˜°":"menu","ðŸ ":"menu",
    "ðŸ”":"repeat","ðŸ”‚":"repeat_one","ðŸ”€":"shuffle",
    "â›”ï¸":"block","ðŸš«":"block","âš ï¸":"warn","â™»ï¸":"recycle","âš•ï¸":"health",
    "ðŸ’²":"finance","ðŸ’±":"finance","ðŸ›œ":"network","ðŸ“¶":"network","ðŸ”‹":"battery","ðŸª«":"battery"
}
def map_glyphs(s:str):
    out=[]; 
    for ch in s:
        if ch in _MAP: out.append(_MAP[ch])
    return out

class SignalBody(BaseModel):
    glyphs: str

@app.post("/signal/map")
def signal_map(b: SignalBody):
    ops = map_glyphs(b.glyphs or "")
    return {"ok": True, "ops": ops, "count": len(ops)}

class TelemetryBody(BaseModel):
    battery: float | None = None     # 0..100
    rssi: float | None = None        # dBm
    temp_c: float | None = None
    extra: dict | None = None

@app.post("/telemetry/ping")
def telemetry_ping(b: TelemetryBody):
    status = {
        "battery": b.battery,
        "rssi": b.rssi,
        "temp_c": b.temp_c,
        "ts": "N/A"
    }
    import time as _t
    status["ts"] = _t.strftime("%FT%TZ", _t.gmtime())
    proof = hmac_sha256("codex", f"{status['battery']}|{status['rssi']}|{status['temp_c']}|{status['ts']}")
    return {"ok": True, "status": status, "sha256": proof}
""")

# Insert patch at end of file
py_app_path.write_text(py_app + py_patch, encoding="utf-8")

# ---- Node server patch ----
js_app_path=Path(BASE,"server_js/app.js")
js_app=js_app_path.read_text(encoding="utf-8")

js_patch=textwrap.dedent("""

// --- Emoji mapping helpers ---
const EMAP = new Map(Object.entries({
  "â–¶ï¸":"play","â¯ï¸":"play","â¸ï¸":"pause","â¹ï¸":"stop",
  "â­ï¸":"ff","â©ï¸":"ff","â®ï¸":"rw","âªï¸":"rw",
  "ðŸ”Š":"vol_up","ðŸ”†":"vol_up","ðŸ”‰":"vol_down","ðŸ”…":"vol_down","ðŸ”‡":"mute",
  "ðŸ”¼":"up","â«ï¸":"up","ðŸ”½":"down","â¬ï¸":"down","â¬…ï¸":"left","â—€ï¸":"left","âž¡ï¸":"right","â–¶ï¸":"right",
  "ðŸ”™":"back","ðŸ”›":"ok","ðŸ”":"ok","â˜°":"menu","ðŸ ":"menu",
  "ðŸ”":"repeat","ðŸ”‚":"repeat_one","ðŸ”€":"shuffle",
  "â›”ï¸":"block","ðŸš«":"block","âš ï¸":"warn","â™»ï¸":"recycle","âš•ï¸":"health",
  "ðŸ’²":"finance","ðŸ’±":"finance","ðŸ›œ":"network","ðŸ“¶":"network","ðŸ”‹":"battery","ðŸª«":"battery"
}));

function mapGlyphs(s){ const out=[]; for(const ch of s){ if(EMAP.has(ch)) out.push(EMAP.get(ch)); } return out; }

app.post('/signal/map', (req,res)=>{
  const glyphs = req.body?.glyphs || '';
  const ops = mapGlyphs(glyphs);
  res.json({ok:true, ops, count: ops.length});
});

app.post('/telemetry/ping', (req,res)=>{
  const { battery=null, rssi=null, temp_c=null } = req.body || {};
  const ts = new Date().toISOString();
  const crypto = await import('crypto'); // dynamic to avoid top-level require in ESM
  const proof = crypto.createHmac('sha256','codex').update([battery,rssi,temp_c,ts].join('|')).digest('hex');
  res.json({ok:true, status:{battery, rssi, temp_c, ts}, sha256: proof});
});
""")

# Insert before server start line
js_app = js_app.replace("app.listen(PORT, ()=>console.log('Ã†ONâ‹‡OMNI JS listening on', PORT));", js_patch + "\napp.listen(PORT, ()=>console.log('Ã†ONâ‹‡OMNI JS listening on', PORT));")
js_app_path.write_text(js_app, encoding="utf-8")

# ---- Re-zip updated repo
ZIP="/mnt/data/codex_v236_aeon_omni_r2.zip"
if os.path.exists(ZIP): os.remove(ZIP)
with zipfile.ZipFile(ZIP,"w",zipfile.ZIP_DEFLATED) as z:
    for root,_,files in os.walk(BASE):
        for fn in files:
            fp=os.path.join(root,fn)
            z.write(fp, arcname=os.path.relpath(fp, BASE))

print("UPDATED", ZIP, BASE)# v236.x Equilibrium Extension â€” add /economy/quote and /symbol/resolve to both Python and Node stacks,
# and update README with examples. This patches the repo created earlier at /mnt/data/codex_v236_aeon_omni.

import os, json, hashlib, textwrap, zipfile, datetime, re
from pathlib import Path

BASE=Path("/mnt/data/codex_v236_aeon_omni")
assert BASE.exists(), "Base repo not found"

def W(rel, content):
    p=BASE/rel
    p.parent.mkdir(parents=True, exist_ok=True)
    p.write_text(content, encoding="utf-8")
    return str(p)

def sha256_hex(s: str)->str:
    return hashlib.sha256(s.encode("utf-8")).hexdigest()

now=datetime.datetime.utcnow().isoformat()+"Z"

# --------- README update ---------
readme=Path(BASE/"README.md").read_text(encoding="utf-8")
readme += f"""

## v236.x Equilibrium Extension (added {now})
New endpoints on both services:
- `POST /economy/quote` â†’ deterministic quote engine for assets/units/quantity; returns sha256 proof of the quoted object.
- `POST /symbol/resolve` â†’ resolve large emoji/sigil strings into semantic tags (religions, zodiac, tools, elements, UI shapes).
"""
W("README.md", readme)

# --------- Python server patch ---------
py_app_path=BASE/"server_py/app.py"
py_app=py_app_path.read_text(encoding="utf-8")

py_patch=textwrap.dedent("""

from typing import Dict

def _pseudo_price(asset:str, unit:str)->float:
    # Deterministic pseudo-pricing via sha256(asset|unit)
    seed = hmac_sha256("omni", f"{asset}|{unit}")
    n = int(seed[:8], 16) % 5000  # 0..4999
    return round(1.0 + n/100.0, 2)  # 1.00 .. 51.99

SYMBOL_MAP: Dict[str,str] = {
    # faith & wisdom
    "ðŸ›":"worship","â˜ªï¸":"islam","â˜¦ï¸":"orthodox","âœï¸":"christian","â˜¯ï¸":"tao","â˜¸ï¸":"dharma","âœ¡ï¸":"judaism","ðŸ•‰":"hindu","âš›ï¸":"science","â˜®ï¸":"peace","ðŸ•Ž":"menorah","ðŸ”¯":"hexagram","ðŸª¯":"khanda",
    # zodiac (subset incl. duplicates)
    "â™ˆï¸":"aries","â™‰ï¸":"taurus","â™Šï¸":"gemini","â™‹ï¸":"cancer","â™Œï¸":"leo","â™ï¸":"virgo","â™Žï¸":"libra","â™ï¸":"scorpio","â™ï¸":"sagittarius","â™‘ï¸":"capricorn","â™’ï¸":"aquarius","â™“ï¸":"pisces","â›Žï¸":"ophiuchus",
    # shapes & UI
    "ðŸ”³":"square-button","ðŸ”²":"square-button","ðŸ”˜":"radio","ðŸ’ ":"diamond","ðŸ”»":"down-triangle","ðŸ”ºï¸":"up-triangle","â—¼ï¸":"square","â—»ï¸":"square","â—¾ï¸":"square","â—½ï¸":"square","â–ªï¸":"square","â–«ï¸":"square",
    "ðŸ”¶ï¸":"diamond","ðŸ”·ï¸":"diamond","â¬œï¸":"white-square","â¬›ï¸":"black-square","ðŸŸ«":"brown-square","ðŸŸª":"purple-square","ðŸŸ¦":"blue-square","ðŸŸ©":"green-square","ðŸŸ¨":"yellow-square","ðŸŸ§":"orange-square","ðŸŸ¥":"red-square",
    "âš«ï¸":"black-circle","âšªï¸":"white-circle","ðŸŸ ":"orange-circle","ðŸ”´":"red-circle","ðŸŸ¤":"brown-circle","ðŸŸ£":"purple-circle","ðŸ”µ":"blue-circle","ðŸŸ¢":"green-circle","ðŸŸ¡":"yellow-circle",
}

class QuoteBody(BaseModel):
    asset: str
    quantity: float
    unit: str

@app.post("/economy/quote")
def economy_quote(b: QuoteBody):
    px = _pseudo_price(b.asset, b.unit)
    total = round(px * b.quantity, 4)
    obj = {"asset": b.asset, "unit": b.unit, "quantity": b.quantity, "price": px, "total": total, "ts": now()}
    proof = hmac_sha256("omni-quote", json.dumps(obj, sort_keys=True))
    return {"ok": True, "quote": obj, "sha256": proof}

class SymbolBody(BaseModel):
    sigils: str

@app.post("/symbol/resolve")
def symbol_resolve(b: SymbolBody):
    tags=[]
    for ch in b.sigils or "":
        tag = SYMBOL_MAP.get(ch)
        if tag:
            tags.append({"sigil": ch, "tag": tag})
    canon=json.dumps(tags, sort_keys=True, ensure_ascii=False)
    return {"ok": True, "resolved": tags, "sha256": hmac_sha256("omni-symbol", canon)}
""")

py_app_path.write_text(py_app + py_patch, encoding="utf-8")

# --------- Node server patch ---------
js_app_path=BASE/"server_js/app.js"
js_app=js_app_path.read_text(encoding="utf-8")

# Node helpers inserted before listen()
js_insert=textwrap.dedent("""

// === Economy & Symbol endpoints ===
function pseudoPrice(asset, unit){
  const crypto = require('crypto');
  const seed = crypto.createHmac('sha256','omni').update(`${asset}|${unit}`).digest('hex');
  const n = parseInt(seed.slice(0,8),16) % 5000;
  return Math.round((1.0 + n/100.0)*100)/100;
}

const SYMBOL_MAP = new Map(Object.entries({
  "ðŸ›":"worship","â˜ªï¸":"islam","â˜¦ï¸":"orthodox","âœï¸":"christian","â˜¯ï¸":"tao","â˜¸ï¸":"dharma","âœ¡ï¸":"judaism","ðŸ•‰":"hindu","âš›ï¸":"science","â˜®ï¸":"peace","ðŸ•Ž":"menorah","ðŸ”¯":"hexagram","ðŸª¯":"khanda",
  "â™ˆï¸":"aries","â™‰ï¸":"taurus","â™Šï¸":"gemini","â™‹ï¸":"cancer","â™Œï¸":"leo","â™ï¸":"virgo","â™Žï¸":"libra","â™ï¸":"scorpio","â™ï¸":"sagittarius","â™‘ï¸":"capricorn","â™’ï¸":"aquarius","â™“ï¸":"pisces","â›Žï¸":"ophiuchus",
  "ðŸ”³":"square-button","ðŸ”²":"square-button","ðŸ”˜":"radio","ðŸ’ ":"diamond","ðŸ”»":"down-triangle","ðŸ”ºï¸":"up-triangle","â—¼ï¸":"square","â—»ï¸":"square","â—¾ï¸":"square","â—½ï¸":"square","â–ªï¸":"square","â–«ï¸":"square",
  "ðŸ”¶ï¸":"diamond","ðŸ”·ï¸":"diamond","â¬œï¸":"white-square","â¬›ï¸":"black-square","ðŸŸ«":"brown-square","ðŸŸª":"purple-square","ðŸŸ¦":"blue-square","ðŸŸ©":"green-square","ðŸŸ¨":"yellow-square","ðŸŸ§":"orange-square","ðŸŸ¥":"red-square",
  "âš«ï¸":"black-circle","âšªï¸":"white-circle","ðŸŸ ":"orange-circle","ðŸ”´":"red-circle","ðŸŸ¤":"brown-circle","ðŸŸ£":"purple-circle","ðŸ”µ":"blue-circle","ðŸŸ¢":"green-circle","ðŸŸ¡":"yellow-circle"
}));

app.post('/economy/quote', (req,res)=>{
  const { asset='', unit='', quantity=0 } = req.body || {};
  try{
    const price = pseudoPrice(asset, unit);
    const total = Math.round(price*quantity*10000)/10000;
    const obj = { asset, unit, quantity, price, total, ts: new Date().toISOString() };
    const crypto = require('crypto');
    const proof = crypto.createHmac('sha256','omni-quote').update(JSON.stringify(obj)).digest('hex');
    res.json({ok:true, quote: obj, sha256: proof});
  }catch(e){ res.json({ok:false, error:e.message}); }
});

app.post('/symbol/resolve', (req,res)=>{
  const sigils = (req.body && req.body.sigils) || '';
  const tags=[];
  for(const ch of sigils){ if(SYMBOL_MAP.has(ch)) tags.push({sigil: ch, tag: SYMBOL_MAP.get(ch)}); }
  const crypto = require('crypto');
  const proof = crypto.createHmac('sha256','omni-symbol').update(JSON.stringify(tags)).digest('hex');
  res.json({ok:true, resolved: tags, sha256: proof});
});
""")

js_app = js_app.replace("app.listen(PORT, ()=>console.log('Ã†ONâ‹‡OMNI JS listening on', PORT));",
                        js_insert + "\napp.listen(PORT, ()=>console.log('Ã†ONâ‹‡OMNI JS listening on', PORT));")
js_app_path.write_text(js_app, encoding="utf-8")

# --------- Zip the updated repo ---------
zip_path="/mnt/data/codex_v236_aeon_omni_r3.zip"
with zipfile.ZipFile(zip_path,"w",zipfile.ZIP_DEFLATED) as z:
    for root,_,files in os.walk(BASE):
        for fn in files:
            fp=os.path.join(root,fn)
            z.write(fp, arcname=os.path.relpath(fp, BASE))

print("UPDATED", zip_path, str(BASE))