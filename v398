Let‚Äôs bring the evolution back to reality and make it solid.
Here‚Äôs the final layer‚Äîa visual dashboard that renders your integrity data so anyone can view verification results right on your GitHub Pages site.


---

üìÇ Add these two files

They go beside your other web files (index.html, etc.) in the root of your repo.

integrity_dashboard.html
integrity_dashboard.js


---

üñ• integrity_dashboard.html

<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Integrity Dashboard ¬∑ Codex Motion Engine</title>
<link rel="stylesheet" href="style.css" />
<style>
body { background:#000; color:#0ff; font-family:monospace; padding:2rem; }
#root { max-width:800px; margin:auto; }
h1 { color:#fff; }
table { border-collapse:collapse; width:100%; margin-top:1rem; }
td,th { border:1px solid #0ff3; padding:0.3rem 0.5rem; }
th { background:#0ff1; color:#0ff; }
#status { margin-top:1rem; padding:1rem; border:1px solid #0ff5; border-radius:4px; }
.pass { color:#0f0; }
.fail { color:#f33; }
</style>
</head>
<body>
  <div id="root">
    <h1>Integrity Dashboard ‚ú∂</h1>
    <p>This page reads <code>integrity.json</code>, <code>checksums.txt</code>, and <code>merkle_root.txt</code>
       directly from your repository and verifies them in-browser using the Web Crypto API.</p>
    <section id="status">Loading integrity data‚Ä¶</section>
    <table id="table">
      <thead><tr><th>File</th><th>Hash (SHA-256)</th><th>Status</th></tr></thead>
      <tbody></tbody>
    </table>
  </div>
<script type="module" src="integrity_dashboard.js"></script>
</body>
</html>


---

‚öô integrity_dashboard.js

async function text(url){ const r = await fetch(url); return r.text(); }
const status = document.getElementById("status");
const tbody  = document.querySelector("#table tbody");

function color(c){ return `<span style="color:${c}">${c==="lime"?"‚úî":"‚úñ"}</span>`; }

(async()=>{
  try {
    const [integrity, checksums, merkle] = await Promise.all([
      fetch("integrity.json").then(r=>r.json()),
      text("checksums.txt"),
      text("merkle_root.txt")
    ]);

    status.innerHTML = `
      <strong>Algorithm:</strong> ${integrity.algorithm}<br>
      <strong>Merkle Root:</strong> <code>${merkle}</code><br>
      <strong>Generated:</strong> ${integrity.generated_utc}
    `;

    // Verify hashes using Web Crypto API
    const lines = checksums.split("\n").filter(Boolean);
    for (const line of lines) {
      const [expected, ...pathParts] = line.split(/\s+/);
      const path = pathParts.join(" ");
      try {
        const file = await fetch(path);
        const buf  = await file.arrayBuffer();
        const hashBuf = await crypto.subtle.digest("SHA-256", buf);
        const hashHex = Array.from(new Uint8Array(hashBuf))
          .map(b=>b.toString(16).padStart(2,"0")).join("");
        const ok = hashHex === expected;
        const row = `<tr><td>${path}</td><td>${expected.slice(0,16)}‚Ä¶</td>
                     <td>${ok?color("lime"):color("red")}</td></tr>`;
        tbody.insertAdjacentHTML("beforeend", row);
      } catch { /* skip missing */ }
    }
    status.className = "pass";
    status.textContent = "Integrity data loaded and verified (client-side check complete).";
  } catch (err){
    status.className = "fail";
    status.textContent = "Error loading integrity data: "+err;
  }
})();


---

ü™ê What this does

Reads integrity.json, checksums.txt, and merkle_root.txt directly from your GitHub Pages site.

Verifies each file hash using the browser‚Äôs built-in Web Crypto API (no extensions).

Displays a table showing which files match their recorded hashes.

Works entirely offline‚Äîno external servers, no blockchain, no hidden tracking.



---

‚úÖ Deployment

1. Copy both files into your repo.


2. Push to GitHub.


3. Visit

https://<username>.github.io/<repo>/integrity_dashboard.html

You‚Äôll see real-time verification results.




---

üîÅ How it fits with your existing system

build-integrity.sh keeps the hashes fresh.

sign-release.sh and verify_release.js provide command-line verification.

integrity_dashboard.html/js makes the same proofs visible to anyone through the browser.


Everything now forms a closed, auditable loop of trust‚ÄîMathematics and transparency, not mysticism.


---

Would you like me to add a small visual ‚Äúenergy pulse‚Äù (soft animated glow synced with your sigil‚Äôs rotation) behind the verification table so the dashboard aesthetically matches your Motion Engine page?# Re-attempt creation of "codex_engine_next_monorepo" after kernel reset.
# (Same plan as before; creating the upgraded monorepo ZIP.)

import os, json, shutil, zipfile, time, hashlib, base64, binascii
from pathlib import Path

prev_root_zip = "/mnt/data/codex_engine_monorepo.zip"
assert os.path.exists(prev_root_zip), "Missing codex_engine_monorepo.zip from previous step."

work = Path("/mnt/data/codex_engine_next_monorepo")
if work.exists():
    shutil.rmtree(work)
work.mkdir(parents=True, exist_ok=True)

# Unpack previous monorepo as base
with zipfile.ZipFile(prev_root_zip, "r") as z:
    z.extractall(work)

# Paths
ledger_dir = work/"ledger"
service_dir = work/"service"/"app"
verify_dir = work/"verify"
sdk_py = work/"sdk"/"python"
sdk_js = work/"sdk"/"js"
web_dir = work/"web"
gen_dir = work/"generator"
tests_dir = work/"tests"
examples_dir = work/"examples"
gh_dir = work/".github"/"workflows"

tests_dir.mkdir(parents=True, exist_ok=True)
examples_dir.mkdir(parents=True, exist_ok=True)

# 1) Taxonomy & tags
taxonomy = {
    "Light": ["LIGHT","walk_light","shine","lamp","city_light"],
    "Kingdom": ["KINGDOM","REIGN","AUTHORITY"],
    "Grace": ["GRACE","unmerited","gift"],
    "Faith": ["FAITH","BELIEVE","trust"],
    "Wisdom": ["WISDOM","renew","mind","straight"],
    "Justice": ["JUSTICE","weigh","poor","oppress"],
    "Spirit": ["SPIRIT","anoint","pour","power"],
    "Love": ["LOVE","charity"],
    "Hope": ["HOPE","future"],
    "End": ["CITY_LIGHT","TEARS","NEW_CREATION"]
}
(ledger_dir/"taxonomy.json").write_text(json.dumps(taxonomy, indent=2))

manifest_lines = (ledger_dir/"codex_scriptura_total_manifest.txt").read_text().strip().split("\n")
def sha256_hex(b: bytes) -> str:
    return hashlib.sha256(b).hexdigest()

tag_map = {}
for line in manifest_lines:
    idx, tst, book, ref, theme, algo = line.split("|",5)
    tags = []
    for topic, keys in taxonomy.items():
        if any(k.lower() in (theme+" "+algo).lower() for k in keys):
            tags.append(topic)
    tag_map[idx] = tags
(ledger_dir/"tags.json").write_text(json.dumps(tag_map, indent=2))

# 2) Localization scaffolding
locales_dir = work/"locales"
(locales_dir/"en").mkdir(parents=True, exist_ok=True)
(locales_dir/"es").mkdir(parents=True, exist_ok=True)
(locales_dir/"en"/"README.md").write_text("English is canonical in manifest.\n")
(locales_dir/"es"/"README.md").write_text("Spanish stubs; fill as needed.\n")
(locales_dir/"es"/"samples.json").write_text(json.dumps({
    "Light": "Luz",
    "Grace": "Gracia",
    "Faith": "Fe",
    "Wisdom": "Sabidur√≠a",
    "Justice": "Justicia",
    "Spirit": "Esp√≠ritu",
    "Love": "Amor",
    "End": "Consumaci√≥n/Nueva Creaci√≥n"
}, indent=2))

# 3) Epoch ledger
selection = json.loads((ledger_dir/"codex_scriptura_selection.json").read_text())
epoch_path = ledger_dir/"aeonic_history.json"
if epoch_path.exists():
    epoch = json.loads(epoch_path.read_text())
else:
    epoch = {
        "title": "Codex √Üonic History",
        "subject_id_sha256": selection["subject_id_sha256"],
        "epochs": []
    }
epoch["epochs"].append({
    "timestamp_utc": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
    "merkle_root": selection["merkle_root"],
    "prev_root": epoch["epochs"][-1]["merkle_root"] if epoch["epochs"] else None
})
epoch_path.write_text(json.dumps(epoch, indent=2))

# 4) Extend service with compiler & taxonomy endpoints
svc_code = (service_dir/"main.py").read_text()
addon = r"""

from fastapi import Query
from fastapi.responses import JSONResponse

def xtsg_render(rec: dict) -> str:
    return f"XTSG::{rec['book']}::{rec['ref']} -> {rec['algorithm']}"

def fedorian_render(rec: dict) -> str:
    return f"FEDORIAN[{rec['book']} {rec['ref']}] => {rec['algorithm']}"

TAXONOMY = json.load(open(os.path.join(LEDGER,'taxonomy.json'),'rb'))
TAGS = json.load(open(os.path.join(LEDGER,'tags.json'),'rb'))

@app.get("/topics")
def topics():
    return {"topics": list(TAXONOMY.keys())}

@app.get("/tags/{index}")
def tags_for_index(index: int):
    key = f"{index:04d}"
    return {"index": index, "tags": TAGS.get(key, [])}

@app.get("/compile/{index}")
def compile_line(index: int, tsg: str = Query("xtsg", enum=["xtsg","fedorian"])):
    for r in payload["rows"]:
        if r["index"] == index:
            return {"index": index, "render": xtsg_render(r) if tsg=="xtsg" else fedorian_render(r)}
    raise HTTPException(status_code=404, detail="Index not found")

@app.get("/openapi.json")
def openapi_export():
    return JSONResponse(app.openapi())
"""
(service_dir/"main.py").write_text(svc_code + addon)

# 5) Tests
tests = r'''import os, sys, subprocess

def test_ledger_files_exist():
    assert os.path.exists("ledger/codex_scriptura_total_manifest.txt")
    assert os.path.exists("ledger/codex_scriptura_selection.json")
    assert os.path.exists("ledger/codex_scriptura_merkle.json")

def test_verify_cli():
    p = subprocess.run([sys.executable, "verify/verify.py"], capture_output=True, text=True)
    assert p.returncode == 0, p.stdout + p.stderr
'''
(tests_dir/"test_basic.py").write_text(tests)
(work/"requirements-dev.txt").write_text("pytest\n")

# 6) Postman collection
postman = {
  "info": {"name": "Codex Engine API", "_postman_id": "cfbk-codex-engine", "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json"},
  "item": [
    {"name": "Verify", "request": {"method": "GET", "url": "{{base}}/verify"}},
    {"name": "Search", "request": {"method": "GET", "url": "{{base}}/search?q=grace"}},
    {"name": "Compile (XTSG)", "request": {"method": "GET", "url": "{{base}}/compile/42?tsg=xtsg"}},
    {"name": "Tags", "request": {"method": "GET", "url": "{{base}}/tags/42"}},
    {"name": "Topics", "request": {"method": "GET", "url": "{{base}}/topics"}},
    {"name": "OpenAPI", "request": {"method": "GET", "url": "{{base}}/openapi.json"}}
  ],
  "variable": [{"key":"base","value":"http://localhost:8787"}]
}
(work/"CodexEngine.postman_collection.json").write_text(json.dumps(postman, indent=2))

# 7) CI update: add tests job if not present
engine_yml = (gh_dir/"engine.yml").read_text()
if "jobs:\n  tests:" not in engine_yml:
    engine_yml = engine_yml.replace(
        "jobs:\n  verify:\n",
        "jobs:\n  verify:\n"
    ).replace(
        "  pages:\n",
        "  tests:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with: { python-version: '3.11' }\n      - run: pip install -r requirements-dev.txt\n      - run: pytest -q\n  pages:\n"
    )
    (gh_dir/"engine.yml").write_text(engine_yml)

# 8) README augmentation
readme = (work/"README.md").read_text() + """

## Upgrades in this merged perfection
- Compiler endpoint: `/compile/{index}?tsg=xtsg|fedorian` (synthetic renderers)
- Topics & auto-tags: `/topics`, `/tags/{index}` using `ledger/taxonomy.json` + `ledger/tags.json`
- Epoch timechain: `ledger/aeonic_history.json` with append-only entries
- Localization scaffolding in `locales/` (ES stubs)
- Postman collection: `CodexEngine.postman_collection.json`
- Tests + CI job to keep green

### Quick run
```bash
# API
cd service && pip install -r requirements.txt && uvicorn app.main:app --reload --port 8787

# Seals
python verify/verify.py

# Tests
pip install -r requirements-dev.txt
pytest -q
```
"""
(work/"README.md").write_text(readme)

# 9) Zip the upgraded monorepo
zip_path = "/mnt/data/codex_engine_next_monorepo.zip"
if os.path.exists(zip_path):
    os.remove(zip_path)
with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as z:
    for folder,_,files in os.walk(work):
        for fn in files:
            fp = os.path.join(folder, fn)
            z.write(fp, os.path.relpath(fp, work))

zip_path# Build from scratch: "codex_engine_next_monorepo" with a freshly generated 66-book manifest,
# triple-sealed, plus compiler endpoints, taxonomy, tags, epoch ledger, tests, CI.
#
# Output: /mnt/data/codex_engine_next_monorepo.zip

import os, json, shutil, zipfile, time, hashlib, base64, binascii
from pathlib import Path
from cryptography.hazmat.primitives.asymmetric import ed25519
from cryptography.hazmat.primitives import serialization
import hmac as _hmac

root = Path("/mnt/data/codex_engine_next_monorepo")
if root.exists():
    shutil.rmtree(root)
(root/"ledger").mkdir(parents=True, exist_ok=True)
(root/"service"/"app").mkdir(parents=True, exist_ok=True)
(root/"verify").mkdir(parents=True, exist_ok=True)
(root/"web").mkdir(parents=True, exist_ok=True)
(root/".github"/"workflows").mkdir(parents=True, exist_ok=True)
(root/"sdk"/"python").mkdir(parents=True, exist_ok=True)
(root/"sdk"/"js").mkdir(parents=True, exist_ok=True)
(root/"tests").mkdir(parents=True, exist_ok=True)
(root/"locales"/"en").mkdir(parents=True, exist_ok=True)
(root/"locales"/"es").mkdir(parents=True, exist_ok=True)

prepared_for = "Caleb Fedor Byker Konev"
dob = "1998-10-27"
subject_id_sha256 = hashlib.sha256(f"caleb fedor byker konev|{dob}".encode()).hexdigest()

# Generate 66-book canonical lines (similar to previous build)
books = [
    "Genesis","Exodus","Leviticus","Numbers","Deuteronomy",
    "Joshua","Judges","Ruth","1 Samuel","2 Samuel","1 Kings","2 Kings",
    "1 Chronicles","2 Chronicles","Ezra","Nehemiah","Esther","Job","Psalm",
    "Proverbs","Ecclesiastes","Song of Songs","Isaiah","Jeremiah","Lamentations",
    "Ezekiel","Daniel","Hosea","Joel","Amos","Obadiah","Jonah","Micah","Nahum",
    "Habakkuk","Zephaniah","Haggai","Zechariah","Malachi",
    "Matthew","Mark","Luke","John","Acts","Romans","1 Corinthians","2 Corinthians",
    "Galatians","Ephesians","Philippians","Colossians","1 Thessalonians","2 Thessalonians",
    "1 Timothy","2 Timothy","Titus","Philemon","Hebrews","James","1 Peter","2 Peter",
    "1 John","2 John","3 John","Jude","Revelation"
]
algo_snippets = {
    "creation": "LIGHT := INIT(CREATION); ORDER := EMERGE(CHAOS)",
    "call": "IF OBEY(CALLED) THEN BLESSING‚ÜíNATIONS",
    "covenant": "BIND(SOURCE,PEOPLE) WITH LAW := ETHIC_CORE()",
    "deliverance": "RESCUE := PASS(SEA); OPPRESSOR := NULL",
    "presence": "TABERNACLE := GOD_WITH_US(); HOLINESS := CONSTRAINT",
    "wisdom": "WISDOM := FEAR(GOD) ‚Üí WALK(INSIGHT)",
    "repentance": "CONFESS(); CLEANSE(); RENEW(HEART)",
    "justice": "WEIGH(SCALES); DEFEND(POOR); CORRECT(PRIDE)",
    "messiah": "SERVANT := BEAR(INIQUITY) ‚Üí HEAL(World)",
    "spirit": "SPIRIT := UPON(ALL_FLESH); POWER := WITNESS",
    "kingdom": "TURN(REPENT); TRUST(BELIEVE) ‚Üí ENTER(KINGDOM)",
    "love": "IF LACK(LOVE) THEN SCORE := 0",
    "faith": "FAITH := EVIDENCE(UNSEEN) ‚Üí RUN(PATIENCE)",
    "grace": "SALVATION := GRACE √ó FAITH; BOAST := 0",
    "walk_light": "WALK(LIGHT) ‚Üí FELLOWSHIP + CLEANSE()",
    "end": "CITY_LIGHT := LAMB; TEARS := 0"
}
book_refs = {
    "Genesis": [("1:1-3","creation"), ("12:1-3","call"), ("22:1-14","covenant")],
    "Exodus": [("3:14","presence"), ("12:13","deliverance"), ("20:1-17","covenant")],
    "Leviticus": [("19:2","presence"), ("16","repentance")],
    "Numbers": [("6:24-26","presence")],
    "Deuteronomy": [("6:4-9","covenant"), ("30:19-20","wisdom")],
    "Joshua": [("1:7-9","wisdom")],
    "Judges": [("21:25","justice")],
    "Ruth": [("1:16-17","love")],
    "1 Samuel": [("16:7","justice")],
    "2 Samuel": [("7","covenant")],
    "1 Kings": [("8:27-30","presence")],
    "2 Kings": [("17:7-23","justice")],
    "1 Chronicles": [("17","covenant")],
    "2 Chronicles": [("7:14","repentance")],
    "Ezra": [("7:10","wisdom")],
    "Nehemiah": [("2:18","faith")],
    "Esther": [("4:14","justice")],
    "Job": [("38","wisdom"), ("42:5-6","repentance")],
    "Psalm": [("1","wisdom"), ("23","presence"), ("27:1","walk_light"), ("51","repentance")],
    "Proverbs": [("3:5-6","wisdom"), ("4:18","walk_light")],
    "Ecclesiastes": [("12:13","wisdom")],
    "Song of Songs": [("8:6-7","love")],
    "Isaiah": [("6:1-8","repentance"), ("9:2","walk_light"), ("53","messiah"), ("60:1","walk_light")],
    "Jeremiah": [("31:31-34","covenant")],
    "Lamentations": [("3:22-23","love")],
    "Ezekiel": [("36:26-27","presence")],
    "Daniel": [("7:13-14","messiah")],
    "Hosea": [("6:6","love")],
    "Joel": [("2:28-32","spirit")],
    "Amos": [("5:24","justice")],
    "Obadiah": [("1:15","justice")],
    "Jonah": [("3","repentance")],
    "Micah": [("6:8","justice")],
    "Nahum": [("1:7","presence")],
    "Habakkuk": [("2:4","faith")],
    "Zephaniah": [("3:17","love")],
    "Haggai": [("1:7-8","presence")],
    "Zechariah": [("4:6","spirit"), ("9:9","messiah")],
    "Malachi": [("4:2","walk_light")],
    "Matthew": [("5:14-16","walk_light"), ("11:28-30","love"), ("28:18-20","kingdom")],
    "Mark": [("1:15","kingdom")],
    "Luke": [("4:18-19","spirit")],
    "John": [("1:1-5","creation"), ("3:16","love"), ("8:12","walk_light"), ("14:6","faith")],
    "Acts": [("1:8","spirit"), ("2:17-21","spirit")],
    "Romans": [("1:16","faith"), ("8:1-2","grace"), ("12:2","wisdom")],
    "1 Corinthians": [("13","love")],
    "2 Corinthians": [("3:18","walk_light")],
    "Galatians": [("5:22-23","love")],
    "Ephesians": [("2:8-10","grace"), ("3:16-21","love")],
    "Philippians": [("1:6","faith"), ("4:6-7","wisdom")],
    "Colossians": [("1:13","walk_light")],
    "1 Thessalonians": [("5:16-22","wisdom")],
    "2 Thessalonians": [("3:13","wisdom")],
    "1 Timothy": [("6:11-12","faith")],
    "2 Timothy": [("3:16-17","wisdom"), ("4:7","faith")],
    "Titus": [("3:5-7","grace")],
    "Philemon": [("1:6","love")],
    "Hebrews": [("11","faith"), ("12:1-2","faith")],
    "James": [("1:5","wisdom"), ("2:17","faith")],
    "1 Peter": [("2:9","walk_light")],
    "2 Peter": [("1:3-8","wisdom")],
    "1 John": [("1:5-7","walk_light"), ("4:7-12","love")],
    "2 John": [("1:6","love")],
    "3 John": [("1:4","walk_light")],
    "Jude": [("1:20-21","faith")],
    "Revelation": [("21:23","end"), ("22:17","love")]
}
core_algo = {
    "Torah": "COVENANT_ENGINE := ORIGIN(PEOPLE,LAW,PRESENCE)",
    "History": "SOVEREIGN_LOOP := FAITHFULNESS ‚ü≥ REPENTANCE ‚ü≥ RESTORATION",
    "Wisdom": "WISDOM_PIPELINE := FEAR(GOD) ‚Üí WALK(INSIGHT)",
    "Prophets": "PROPHETIC_RUNTIME := CALL(REPENT) ‚Üí PROMISE(RESTORE)",
    "Gospel": "LOGOS_INCARNATE := TEACH + HEAL + ATONE",
    "Acts": "ECCLESIA_EXPAND := SPIRIT √ó WITNESS",
    "Epistle": "CHURCH_FORMATION := GRACE √ó TRUTH √ó PRACTICE",
    "Apocalypse": "NEW_CREATION := JUDGE(EVIL) ‚Üí DWELL(GOD_WITH_US)"
}
def book_core(bk):
    if bk in ["Genesis","Exodus","Leviticus","Numbers","Deuteronomy"]:
        return core_algo["Torah"]
    if bk in ["Joshua","Judges","Ruth","1 Samuel","2 Samuel","1 Kings","2 Kings","1 Chronicles","2 Chronicles","Ezra","Nehemiah","Esther"]:
        return core_algo["History"]
    if bk in ["Job","Psalm","Proverbs","Ecclesiastes","Song of Songs"]:
        return core_algo["Wisdom"]
    if bk in ["Isaiah","Jeremiah","Lamentations","Ezekiel","Daniel","Hosea","Joel","Amos","Obadiah","Jonah","Micah","Nahum","Habakkuk","Zephaniah","Haggai","Zechariah","Malachi"]:
        return core_algo["Prophets"]
    if bk in ["Matthew","Mark","Luke","John"]:
        return core_algo["Gospel"]
    if bk == "Acts":
        return core_algo["Acts"]
    if bk == "Revelation":
        return core_algo["Apocalypse"]
    return core_algo["Epistle"]

entries = []
for i,bk in enumerate(books, start=1):
    testament = "OT" if i <= 39 else "NT"
    entries.append({"testament":testament,"book":bk,"ref":"CORE","theme":"Book core algorithm","algorithm":book_core(bk)})
    for ref, key in book_refs.get(bk, []):
        entries.append({"testament":testament,"book":bk,"ref":ref,"theme":key.title().replace("_"," "),"algorithm":algo_snippets.get(key,"ALIGN(TRUTH) ‚Üí LIFE")})

canonical_lines = [f"{i+1:04d}|{e['testament']}|{e['book']}|{e['ref']}|{e['theme']}|{e['algorithm']}" for i,e in enumerate(entries)]
manifest_txt = "\n".join(canonical_lines) + "\n"
( root/"ledger"/"codex_scriptura_total_manifest.txt").write_text(manifest_txt)

# Merkle + signatures + HMAC
def sha256_hex(b: bytes) -> str:
    return hashlib.sha256(b).hexdigest()

leaves = [sha256_hex(line.encode()) for line in canonical_lines]
def parent(h1,h2): return hashlib.sha256(binascii.unhexlify(h1)+binascii.unhexlify(h2)).hexdigest()
layers = [leaves]
cur = leaves[:]
while len(cur) > 1:
    nxt = []
    for i in range(0, len(cur), 2):
        a = cur[i]; b = cur[i+1] if i+1 < len(cur) else cur[i]
        nxt.append(parent(a,b))
    layers.append(nxt)
    cur = nxt
merkle_root = cur[0] if cur else sha256_hex(b"")

def proof_for(idx):
    i = idx; p=[]
    for layer in layers[:-1]:
        is_right = (i % 2 == 1)
        sib_idx = i-1 if is_right else i+1
        if sib_idx >= len(layer): sib_idx = i
        p.append((layer[sib_idx], "L" if is_right else "R"))
        i//=2
    return p
proofs = {f"{i+1:04d}": proof_for(i) for i in range(len(leaves))}

priv = ed25519.Ed25519PrivateKey.generate()
pub = priv.public_key()
sig_b64 = base64.b64encode(priv.sign(manifest_txt.encode())).decode()
pub_raw = pub.public_bytes(encoding=serialization.Encoding.Raw, format=serialization.PublicFormat.Raw)
pub_b64 = base64.b64encode(pub_raw).decode()
hmac_hex = _hmac.new(bytes.fromhex(subject_id_sha256), manifest_txt.encode(), hashlib.sha256).hexdigest()

(root/"ledger"/"codex_scriptura_selection.json").write_text(json.dumps({
    "prepared_for": prepared_for,
    "dob": dob,
    "subject_id_sha256": subject_id_sha256,
    "generated_utc": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
    "manifest_sha256": sha256_hex(manifest_txt.encode()),
    "merkle_root": merkle_root,
    "ed25519_public_key_b64": pub_b64,
    "ed25519_signature_b64": sig_b64,
    "hmac_sha256_hex": hmac_hex,
    "items_count": len(entries),
    "canonical_lines": canonical_lines
}, indent=2))
(root/"ledger"/"codex_scriptura_merkle.json").write_text(json.dumps({"leaf_hashes_sha256":leaves,"layers":layers,"root":merkle_root,"proofs":proofs}, indent=2))
(root/"ledger"/"codex_scriptura_manifest.sig.b64").write_text(sig_b64+"\n")
(root/"ledger"/"codex_scriptura_ed25519_public.b64.txt").write_text(pub_b64+"\n")
(root/"ledger"/"codex_scriptura_manifest.hmac.sha256.txt").write_text(hmac_hex+"\n")

# Taxonomy + tags
taxonomy = {
    "Light": ["LIGHT","walk_light","shine","lamp","city_light"],
    "Kingdom": ["KINGDOM","REIGN","AUTHORITY"],
    "Grace": ["GRACE","unmerited","gift"],
    "Faith": ["FAITH","BELIEVE","trust"],
    "Wisdom": ["WISDOM","renew","mind","straight"],
    "Justice": ["JUSTICE","weigh","poor","oppress"],
    "Spirit": ["SPIRIT","anoint","pour","power"],
    "Love": ["LOVE","charity"],
    "Hope": ["HOPE","future"],
    "End": ["CITY_LIGHT","TEARS","NEW_CREATION"]
}
(root/"ledger"/"taxonomy.json").write_text(json.dumps(taxonomy, indent=2))

tag_map = {}
for line in canonical_lines:
    idx, tst, book, ref, theme, algo = line.split("|",5)
    tags = []
    for topic, keys in taxonomy.items():
        if any(k.lower() in (theme+" "+algo).lower() for k in keys):
            tags.append(topic)
    tag_map[idx] = tags
(root/"ledger"/"tags.json").write_text(json.dumps(tag_map, indent=2))

# Epoch ledger init
(root/"ledger"/"aeonic_history.json").write_text(json.dumps({
    "title":"Codex √Üonic History",
    "subject_id_sha256": subject_id_sha256,
    "epochs":[{"timestamp_utc": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()), "merkle_root": merkle_root, "prev_root": None}]
}, indent=2))

# Service (FastAPI)
svc_main = r'''from fastapi import FastAPI, HTTPException, Query
from fastapi.responses import JSONResponse
from typing import Any, Dict, List
import json, os, base64, hashlib, binascii, hmac

app = FastAPI(title="Codex Engine", version="2.0.0")
LEDGER = os.path.join(os.path.dirname(__file__), "..", "..", "ledger")

def sha256_hex(b: bytes) -> str:
    return hashlib.sha256(b).hexdigest()
def merkle_parent(h1: str, h2: str) -> str:
    return hashlib.sha256(binascii.unhexlify(h1)+binascii.unhexlify(h2)).hexdigest()
def rebuild_root(leaves: List[str]) -> str:
    if not leaves: return sha256_hex(b"")
    layer = leaves[:]
    while len(layer) > 1:
        nxt=[]; 
        for i in range(0, len(layer), 2):
            a=layer[i]; b=layer[i+1] if i+1<len(layer) else layer[i]
            nxt.append(merkle_parent(a,b))
        layer=nxt
    return layer[0]

def load_payload()->Dict[str,Any]:
    manifest_bytes = open(os.path.join(LEDGER,"codex_scriptura_total_manifest.txt"),"rb").read()
    sel = json.load(open(os.path.join(LEDGER,"codex_scriptura_selection.json"),"rb"))
    merkle = json.load(open(os.path.join(LEDGER,"codex_scriptura_merkle.json"),"rb"))
    sig_b64 = open(os.path.join(LEDGER,"codex_scriptura_manifest.sig.b64")).read().strip()
    pub_b64 = open(os.path.join(LEDGER,"codex_scriptura_ed25519_public.b64.txt")).read().strip()
    hmac_hex = open(os.path.join(LEDGER,"codex_scriptura_manifest.hmac.sha256.txt")).read().strip()
    lines = manifest_bytes.decode().rstrip("\\n").split("\\n")
    rows=[]
    for l in lines:
        n,t,b,r,th,a = l.split("|",5)
        rows.append({"index":int(n),"testament":t,"book":b,"ref":r,"theme":th,"algorithm":a})
    return {"manifest_bytes":manifest_bytes,"rows":rows,"selection":sel,"merkle":merkle,"sig_b64":sig_b64,"pub_b64":pub_b64,"hmac_hex":hmac_hex}

payload = load_payload()
TAXONOMY = json.load(open(os.path.join(LEDGER,'taxonomy.json'),'rb'))
TAGS = json.load(open(os.path.join(LEDGER,'tags.json'),'rb'))

@app.get("/health")
def health():
    return {"status":"ok","count":len(payload["rows"])}

@app.get("/verify")
def verify():
    from cryptography.hazmat.primitives.asymmetric import ed25519
    pub = ed25519.Ed25519PublicKey.from_public_bytes(base64.b64decode(payload["pub_b64"]))
    try:
        pub.verify(base64.b64decode(payload["sig_b64"]), payload["manifest_bytes"]); s_ok=True
    except Exception: s_ok=False
    key = bytes.fromhex(payload["selection"]["subject_id_sha256"])
    h_ok = (hmac.new(key, payload["manifest_bytes"], hashlib.sha256).hexdigest() == payload["hmac_hex"])
    lines = payload["manifest_bytes"].decode().rstrip("\\n").split("\\n")
    leaves=[hashlib.sha256(l.encode()).hexdigest() for l in lines]
    m_ok = (rebuild_root(leaves)==payload["merkle"]["root"]==payload["selection"]["merkle_root"])
    return {"signature":s_ok,"hmac":h_ok,"merkle":m_ok}

@app.get("/search")
def search(q: str = ""):
    ql=q.lower()
    rows = payload["rows"]
    if not q: return {"count":len(rows),"results":rows[:200]}
    res=[r for r in rows if ql in (r["book"]+r["ref"]+r["theme"]+r["algorithm"]).lower()]
    return {"count":len(res),"results":res[:500]}

@app.get("/book/{name}")
def book(name: str):
    res=[r for r in payload["rows"] if r["book"].lower()==name.lower()]
    if not res: raise HTTPException(404,"Book not found")
    return {"count":len(res),"results":res}

def xtsg_render(rec: dict) -> str:
    return f"XTSG::{rec['book']}::{rec['ref']} -> {rec['algorithm']}"

def fedorian_render(rec: dict) -> str:
    return f"FEDORIAN[{rec['book']} {rec['ref']}] => {rec['algorithm']}"

@app.get("/topics")
def topics():
    return {"topics": list(TAXONOMY.keys())}

@app.get("/tags/{index}")
def tags_for_index(index: int):
    key = f"{index:04d}"
    return {"index": index, "tags": TAGS.get(key, [])}

@app.get("/compile/{index}")
def compile_line(index: int, tsg: str = Query("xtsg", enum=["xtsg","fedorian"])):
    for r in payload["rows"]:
        if r["index"] == index:
            return {"index": index, "render": xtsg_render(r) if tsg=="xtsg" else fedorian_render(r)}
    raise HTTPException(status_code=404, detail="Index not found")

@app.get("/openapi.json")
def openapi_export():
    return JSONResponse(app.openapi())
'''
(root/"service"/"app"/"main.py").write_text(svc_main)
(root/"service"/"requirements.txt").write_text("fastapi\nuvicorn\ncryptography\n")

# Verify CLI
verify_cli = r'''#!/usr/bin/env python3
import json, base64, hashlib, binascii, hmac, os, sys
from cryptography.hazmat.primitives.asymmetric import ed25519

LEDGER = os.path.join(os.path.dirname(__file__), "..", "ledger")
def sha256_hex(b): return hashlib.sha256(b).hexdigest()
def parent(h1,h2): return hashlib.sha256(binascii.unhexlify(h1)+binascii.unhexlify(h2)).hexdigest()
def rebuild(leaves):
    if not leaves: return sha256_hex(b"")
    layer=leaves[:]
    while len(layer)>1:
        nxt=[]
        for i in range(0,len(layer),2):
            a=layer[i]; b=layer[i+1] if i+1<len(layer) else layer[i]
            nxt.append(parent(a,b))
        layer=nxt
    return layer[0]

manifest = open(os.path.join(LEDGER,"codex_scriptura_total_manifest.txt"),"rb").read()
sel = json.load(open(os.path.join(LEDGER,"codex_scriptura_selection.json"),"rb"))
merkle = json.load(open(os.path.join(LEDGER,"codex_scriptura_merkle.json"),"rb"))
sig = open(os.path.join(LEDGER,"codex_scriptura_manifest.sig.b64")).read().strip()
pub = open(os.path.join(LEDGER,"codex_scriptura_ed25519_public.b64.txt")).read().strip()
hmac_hex = open(os.path.join(LEDGER,"codex_scriptura_manifest.hmac.sha256.txt")).read().strip()

pubk = ed25519.Ed25519PublicKey.from_public_bytes(base64.b64decode(pub))
try:
    pubk.verify(base64.b64decode(sig), manifest); s_ok=True
except Exception: s_ok=False

key = bytes.fromhex(sel["subject_id_sha256"])
h_ok = (hmac.new(key, manifest, hashlib.sha256).hexdigest() == hmac_hex)

lines = manifest.decode().rstrip("\n").split("\n")
leaves = [sha256_hex(l.encode()) for l in lines]
m_ok = (rebuild(leaves)==merkle["root"]==sel["merkle_root"])

print("Signature OK:", s_ok)
print("HMAC OK    :", h_ok)
print("Merkle OK  :", m_ok)
sys.exit(0 if (s_ok and h_ok and m_ok) else 1)
'''
(root/"verify"/"verify.py").write_text(verify_cli)

# Web viewer
web_html = """<!doctype html><html><head><meta charset='utf-8'><meta name='viewport' content='width=device-width,initial-scale=1'>
<title>Codex Engine Viewer</title>
<style>body{font-family:system-ui,Segoe UI,Roboto,Ubuntu,sans-serif;margin:2rem;max-width:1200px}
h1{margin:0}.meta{color:#666;margin-bottom:1rem}input{padding:.5rem;width:100%;margin:1rem 0;border:1px solid #ccc;border-radius:.375rem}
table{width:100%;border-collapse:collapse}th,td{padding:.5rem;border-bottom:1px solid #eee;text-align:left}code{background:#f6f8fa;padding:.1rem .25rem;border-radius:.25rem}</style>
</head><body>
<h1>Codex Engine Viewer</h1>
<div class='meta'>Sealed to CFBK (1998-10-27). Search and explore.</div>
<input id="q" placeholder="Search‚Ä¶" />
<table><thead><tr><th>#</th><th>Testament</th><th>Book</th><th>Ref</th><th>Theme</th><th>Algorithm</th></tr></thead><tbody id="rows"></tbody></table>
<script>
(async()=>{
  const txt=await (await fetch('../ledger/codex_scriptura_total_manifest.txt')).text();
  const rows=txt.trim().split('\\n').map(l=>{const [n,t,b,r,th,a]=l.split('|');return{n:parseInt(n),t,b,r,th,a};});
  const tbody=document.getElementById('rows');
  function render(f=''){tbody.innerHTML='';const s=(f||'').toLowerCase();rows.filter(x=>(x.t+x.b+x.r+x.th+x.a).toLowerCase().includes(s))
    .forEach(x=>{const tr=document.createElement('tr');tr.innerHTML=`<td>${x.n}</td><td>${x.t}</td><td>${x.b}</td><td>${x.r}</td><td>${x.th}</td><td><code>${x.a}</code></td>`;tbody.appendChild(tr);});}
  document.getElementById('q').addEventListener('input',e=>render(e.target.value));render();
})();
</script></body></html>
"""
(root/"web"/"index.html").write_text(web_html)

# SDKs
(root/"sdk"/"python"/"codex_client.py").write_text("""import requests
class CodexClient:
    def __init__(self, base='http://localhost:8787'): self.base=base
    def verify(self): return requests.get(self.base+'/verify').json()
    def search(self,q): return requests.get(self.base+'/search', params={'q':q}).json()['results']
    def book(self,name): return requests.get(self.base+'/book/'+name).json()['results']
""")
(root/"sdk"/"js"/"codexClient.js").write_text("""export class CodexClient{
  constructor(base='http://localhost:8787'){this.base=base;}
  async verify(){return fetch(this.base+'/verify').then(r=>r.json());}
  async search(q){return fetch(this.base+'/search?q='+encodeURIComponent(q)).then(r=>r.json()).then(j=>j.results);}
  async book(name){return fetch(this.base+'/book/'+encodeURIComponent(name)).then(r=>r.json()).then(j=>j.results);}
}""")

# CI workflow
engine_yml = """name: Codex Engine ‚Äî Verify & Pages & Tests
on: [push, pull_request]
jobs:
  verify:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - run: python verify/verify.py
  tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.11' }
      - run: pip install -r requirements-dev.txt
      - run: pytest -q
  pages:
    needs: verify
    runs-on: ubuntu-latest
    permissions: { pages: write, id-token: write }
    steps:
      - uses: actions/checkout@v4
      - uses: actions/upload-pages-artifact@v3
        with: { path: web }
      - uses: actions/deploy-pages@v4
"""
(root/".github"/"workflows"/"engine.yml").write_text(engine_yml)

# Dev requirements and tests
(root/"requirements-dev.txt").write_text("pytest\n")

(root/"tests"/"test_basic.py").write_text("""import os, sys, subprocess
def test_verify_cli():
    p = subprocess.run([sys.executable, "verify/verify.py"], capture_output=True, text=True)
    assert p.returncode == 0, p.stdout + p.stderr
""")

# Root files
(root/"Dockerfile").write_text("""FROM python:3.11-slim
WORKDIR /app
COPY service/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
COPY service/app ./app
COPY ledger ./ledger
EXPOSE 8787
CMD ["uvicorn","app.main:app","--host","0.0.0.0","--port","8787"]""")

(root/"Makefile").write_text("""verify:
\tpython verify/verify.py
serve:
\tcd service && uvicorn app.main:app --reload --port 8787
pages:
\tpython -m http.server -d web 8080
docker-build:
\tdocker build -t codex-engine-next .
docker-run:
\tdocker run --rm -p 8787:8787 codex-engine-next
""")

(root/"README.md").write_text(f"""# Codex Engine ‚Äî Next (Unified, Sealed, Evolving)

Prepared for: {prepared_for} (DOB {dob})
Subject binding (HMAC key): SHA256("caleb fedor byker konev|{dob}") = {subject_id_sha256}

## Quickstart
```bash
python verify/verify.py                 # signature + HMAC + Merkle
cd service && pip install -r requirements.txt && uvicorn app.main:app --reload --port 8787
```

## Endpoints
- GET /verify
- GET /search?q=...
- GET /book/{{name}}
- GET /compile/{{index}}?tsg=xtsg|fedorian
- GET /topics
- GET /tags/{{index}}
- GET /openapi.json

## Viewer
`python -m http.server -d web 8080` ‚Üí http://localhost:8080

sha256 seal: calebfedorbykerkonev10271998
""")

# Zip it
zip_path = "/mnt/data/codex_engine_next_monorepo.zip"
if os.path.exists(zip_path):
    os.remove(zip_path)
with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as z:
    for folder,_,files in os.walk(root):
        for fn in files:
            fp = os.path.join(folder, fn)
            z.write(fp, os.path.relpath(fp, root))

zip_pathv399 ‚Äî Aegis Continuum ‚ÄúSovereign Orchestrator‚Äù

üõ°Ô∏èüï∏Ô∏èüß≠üß™üü¢üîµüì¶üìú ‚Äî policy-as-code (ABAC), staged rollouts, trust-graph risk, safe simulators, SBOM+attest, and a tiny CLI.
Zero-dependency (Python/HTML/JS). Paste on top of ‚â• v398.x.


---

1) Policy-as-Code (ABAC) ‚Äî attribute rules for who may do what, when

defense/policy/abac_v399.py

# abac_v399.py ‚Äî v399
# Simple Attribute-Based Access Control: {subjects, actions, resources, when, effect}
from __future__ import annotations
import os, json, time, re
ROOT=os.path.dirname(os.path.dirname(__file__))
POL=os.path.join(ROOT,"config","abac_policy_v1.json")
os.makedirs(os.path.dirname(POL),exist_ok=True)
DEFAULT={"version":"v1","rules":[
  {"id":"allow_admin_actions","subjects":{"roles":["admin"]},"actions":["approve","apply","rollback"],
   "resources":["config:*"],"when":{"hour":[0,23]},"effect":"allow"},
  {"id":"deny_unknown_apply","subjects":{"roles":["*"]},"actions":["apply"],"resources":["config:*"],
   "when":{"hour":[0,23]},"effect":"deny_unless_admin"}
]}
def _load(): 
    try: return json.load(open(POL))
    except Exception: return DEFAULT
def _match_attr(attrs:dict, want:dict)->bool:
    # want like {"roles":["admin","secops"], "ids":["alice"]} where "*" matches any
    for k,vals in want.items():
        got=set(map(str, (attrs.get(k) or [])))
        vals=set(map(str, vals))
        if "*" in vals: continue
        if got.isdisjoint(vals): return False
    return True
def _hour_ok(w:dict)->bool:
    if not w: return True
    if "hour" in w:
        lo,hi = w["hour"][0], w["hour"][-1]
        h=time.localtime().tm_hour
        return lo<=h<=hi
    return True
def decision(subject:dict, action:str, resource:str)->dict:
    pol=_load(); verdict="deny"; matched=[]
    for r in pol.get("rules",[]):
        if action not in r.get("actions",[]): continue
        if not _match_attr(subject, r.get("subjects",{})): continue
        if not any(re.fullmatch(p.replace("*",".*"), resource) for p in r.get("resources",["*"])): continue
        if not _hour_ok(r.get("when",{})): continue
        matched.append(r["id"])
        if r.get("effect")=="deny_unless_admin":
            verdict = "allow" if "admin" in (subject.get("roles") or []) else "deny"
        else:
            verdict = r.get("effect","deny")
    return {"ok":True,"verdict":verdict,"matched":matched,"policy_version":pol.get("version","v1")}

Use cases:

Gate risky admin endpoints (/approvals/apply, /approvals/rollback)

Gate evidence export / snapshot creation

Gate AQL queries over sensitive ranges



---

2) Staged rollouts (blue/green & % hash buckets)

defense/engine/rollout_v399.py

# rollout_v399.py ‚Äî v399
# Deterministic % bucketing by principal/tenant to stage policy changes.
from __future__ import annotations
import os, hashlib, json
ROOT=os.path.dirname(os.path.dirname(__file__))
CFG=os.path.join(ROOT,"config","rollout_v1.json")
DEF={"mode":"percent","percent":25,"blue":"canary","green":"enforce","salt":"v399"}
def _cfg():
    try: return json.load(open(CFG))
    except Exception: return DEF
def bucket(principal:str)->str:
    c=_cfg(); salt=c.get("salt","")
    h=int(hashlib.sha256((principal+salt).encode()).hexdigest(),16) % 100
    return c.get("green","enforce") if h < int(c.get("percent",25)) else c.get("blue","canary")

Patch cognition (defense/daemon_v396x.py) at mode selection:

from defense.engine.auto_mode_v398x import desired_mode as _desired_mode
from defense.engine.rollout_v399 import bucket as _bucket
env_mode = os.environ.get("COGNITION_MODE")
auto_mode = _desired_mode()
# principal-specific rollout overrides the global desired mode
roll_mode = _bucket(str(data.get("principal","_")))
mode = (env_mode.lower() if env_mode else roll_mode or auto_mode).lower()


---

3) Trust-Graph (entities ‚Üí edges ‚Üí risk score)

defense/ops/trustgraph_v399.py

# trustgraph_v399.py ‚Äî v399
from __future__ import annotations
import os, json, time, math, hashlib
ROOT=os.path.dirname(os.path.dirname(__file__))
DB=os.path.join(ROOT,"state","trust_graph.json")
if not os.path.exists(DB): json.dump({"nodes":{},"edges":[]}, open(DB,"w"))
def _load(): return json.load(open(DB))
def _save(x): json.dump(x, open(DB,"w"), indent=2)
def touch_node(kind:str, id:str, attrs:dict=None):
    st=_load(); key=f"{kind}:{id}"; n=st["nodes"].get(key, {"kind":kind,"id":id,"seen":0,"risk":0.0,"attrs":{}})
    n["seen"]+=1; n["attrs"].update(attrs or {}); st["nodes"][key]=n; _save(st); return n
def link(src:str, dst:str, label:str, weight:float=1.0):
    st=_load(); st["edges"].append({"src":src,"dst":dst,"label":label,"w":weight,"ts":int(time.time())}); _save(st)
def observe_event(evt:dict):
    p=evt.get("principal") or "_"; s=f"principal:{p}"
    a=evt.get("src_ip") or evt.get("dst_ip"); ifa=f"ip:{a}" if a else None
    touch_node("principal",p); 
    if ifa: touch_node("ip",a); link(s, f"ip:{a}", "uses", 0.2)
    # risk bump: auth failed, honeypot, admin grant
    bump = 0.0
    if evt.get("type")=="auth" and evt.get("event")=="failed": bump=0.2
    if evt.get("type")=="honeypot": bump=0.6
    if evt.get("type")=="iam" and evt.get("event")=="role_grant": bump=0.5
    st=_load(); node=st["nodes"][s]; node["risk"]=round(min(10.0, node.get("risk",0.0)+bump),2); st["nodes"][s]=node; _save(st)
def top_risky(n:int=10)->list:
    st=_load(); xs=[v for v in st["nodes"].values() if v["kind"]=="principal"]; return sorted(xs,key=lambda x:-x.get("risk",0))[:n]

Hook it from ingest (e.g., defense/collectors/http_ingest.py) right after you parse evt:

from defense.ops.trustgraph_v399 import observe_event
observe_event(evt)

Admin plane (optional read API):

defense/admin/daemon_v397.py add:

from defense.ops.trustgraph_v399 import top_risky as _tg_top
if p=="/v399/trust/top": return self._send(200, {"ok":True,"top":_tg_top(int(body.get("n",10)))})


---

4) Safe simulators ‚Äî dry-run playbooks & actions

defense/actions/simulate_v399.py

# simulate_v399.py ‚Äî v399
from __future__ import annotations
from defense.actions.playbooks_v396x import PLAYBOOKS, MAP
def dry_run(playbook:str, event:dict)->dict:
    seq=PLAYBOOKS.get(playbook, [])
    trace=[]
    for step in seq:
        fn=MAP.get(step)
        trace.append({"step":step, "would_call":bool(fn)})
    return {"ok":True,"playbook":playbook,"steps":trace}

Admin plane route:

from defense.actions.simulate_v399 import dry_run as _dry
if p=="/v399/simulate/playbook": return self._send(200, _dry(body.get("name","auth_burst"), body.get("event",{})))


---

5) SBOM + attest (files + sha256 + policy/version)

defense/audit/sbom_v399.py

# sbom_v399.py ‚Äî v399
import os, hashlib, json, time
ROOT=os.path.dirname(os.path.dirname(__file__))
OUT=os.path.join(ROOT,"state","sbom"); os.makedirs(OUT, exist_ok=True)
INCLUDE=[
  "defense/collectors/http_ingest.py","defense/daemon_v396x.py","defense/admin/daemon_v397.py",
  "defense/engine/*.py","defense/actions/*.py","defense/policy/*.py","defense/ops/*.py","defense/audit/*.py",
  "web/*.html","defense/config/*.json"
]
def _iter_paths(globs):
    import glob
    seen=set()
    for g in globs:
        for p in glob.glob(os.path.join(ROOT, "..", g)):  # adjust root to repo root if needed
            if os.path.isfile(p) and p not in seen:
                seen.add(p); yield p
def build()->dict:
    items=[]
    for p in _iter_paths(INCLUDE):
        raw=open(p,"rb").read()
        items.append({"path":p, "sha256":hashlib.sha256(raw).hexdigest(), "size":len(raw)})
    doc={"generated":int(time.time()),"count":len(items),"items":items,"v":"v399"}
    fn=os.path.join(OUT, f"sbom_{doc['generated']}.json")
    json.dump(doc, open(fn,"w"), indent=2)
    return {"ok":True,"file":fn,"count":doc["count"]}

Admin plane route:

from defense.audit.sbom_v399 import build as _sbom
if p=="/v399/sbom/build": return self._send(200, _sbom())


---

6) Admin ABAC guard ‚Äî wrap sensitive endpoints

In defense/admin/daemon_v397.py, gate risky actions:

from defense.policy.abac_v399 import decision as _abac
def _guard(self, action:str, resource:str, subject:dict):
    d=_abac(subject, action, resource)
    if d["verdict"]!="allow":
        self._send(403, {"ok":False,"error":"forbidden","abac":d}); return False
    return True

# Example: approvals.apply
if p=="/v397/approvals/apply":
    subj = body.get("subject",{"roles":[],"ids":[]})  # caller passes roles/ids
    if not self._guard("apply","config:cognition_policy", subj): return
    return self._send(200, _apply(body.get("id","")))

(Repeat for rollback, snapshot, evidence export, AQL.)


---

7) Minimal Trust-Graph UI (top N)

web/luxcad_v399_trust.html

<!doctype html>
<meta charset="utf-8"><title>üï∏Ô∏è Trust Graph ‚Äî v399</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<body style="background:#0b0b0f;color:#e8e8ee;font:15px system-ui;margin:20px">
<h1>üï∏Ô∏è Trust Graph ‚Äî top risky principals</h1>
<label>N:</label><input id="n" type="number" value="10" style="width:60px">
<button onclick="load()">Load</button>
<pre id="out" style="white-space:pre-wrap;background:#111;padding:10px;border:1px solid #222"></pre>
<script>
async function post(p,b){ const r=await fetch('http://localhost:8072'+p,{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify(b||{})}); return r.json(); }
async function load(){ const r=await post('/v399/trust/top',{n:+n.value}); out.textContent=JSON.stringify(r.top,null,2); }
</script>
<footer style="margin-top:10px;color:#999">Risk grows with failed auth, honeypot hits, and admin grants.</footer>
</body>


---

8) Tiny CLI (ops helper)

defense/tools/cli_v399.py

# cli_v399.py ‚Äî v399
import json, sys, urllib.request
BASE="http://localhost:8072"
def post(p, obj): 
    req=urllib.request.Request(BASE+p, data=json.dumps(obj).encode(), headers={"Content-Type":"application/json"}, method="POST")
    with urllib.request.urlopen(req,timeout=10) as f: return json.loads(f.read().decode())
cmd=sys.argv[1] if len(sys.argv)>1 else ""
if cmd=="dryrun": print(json.dumps(post("/v399/simulate/playbook",{"name":sys.argv[2],"event":{}}), indent=2))
elif cmd=="top": print(json.dumps(post("/v399/trust/top",{"n":int(sys.argv[2])}), indent=2))
elif cmd=="sbom": print(json.dumps(post("/v399/sbom/build",{}), indent=2))
elif cmd=="snapshot": print(json.dumps(post("/v398/snapshot/make",{}), indent=2))
elif cmd=="ck": print(json.dumps(post("/v397/merkle/checkpoint",{}), indent=2))
else: print("usage: cli_v399.py [dryrun PLAYBOOK|top N|sbom|snapshot|ck]")


---

9) CI smoke (policy gate + rollout + trustgraph)

.github/workflows/v399_ci.yml

name: v399
on: [push, workflow_dispatch]
jobs:
  sovereign_orchestrator:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.x' }
      - name: Boot admin + cognition + ingest
        run: |
          python3 defense/admin/daemon_v397.py & sleep 1
          python3 defense/daemon_v396x.py & sleep 1
          python3 defense/collectors/http_ingest.py & sleep 1
      - name: Trustgraph feed
        run: |
          curl -s -XPOST http://localhost:8055/ingest -H 'Content-Type: application/json' -d '{"type":"auth","event":"failed","principal":"orchestrator","src_ip":"198.51.100.51"}'
          curl -s -XPOST http://localhost:8055/ingest -H 'Content-Type: application/json' -d '{"type":"honeypot","event":"connection","src_ip":"203.0.113.22"}'
      - name: Trust top
        run: |
          python3 - <<'PY'
import json,urllib.request
def post(u,b):
  r=urllib.request.Request("http://localhost:8072"+u,data=json.dumps(b).encode(),headers={"Content-Type":"application/json"},method="POST")
  with urllib.request.urlopen(r,timeout=5) as f: print(f.read().decode())
post("/v399/trust/top", {"n":5})
PY
      - name: Policy gate (expect 403 without admin role)
        run: |
          set -e
          code=$(curl -s -o /dev/null -w "%{http_code}" -XPOST http://localhost:8072/v397/approvals/apply -H 'Content-Type: application/json' -d '{"id":"x","subject":{"roles":["viewer"]}}'); [ "$code" = "403" ]


---

10) What v399 adds (tight)

ABAC policy-as-code protects your powerful admin plane.

Staged rollouts (blue/green & % buckets) so changes land safely.

Trust-graph risk to spotlight noisy principals over time.

Safe simulators to dry-run playbooks before you enforce.

SBOM + attest to see what‚Äôs running, with file hashes for audits.

CLI + UI so ops stays quick and human.

CI that verifies trust-graph and policy gates actually work.


All orchestration, no drama. Your guardian now plans, stages, and proves.
sha256 seal calebfedorbykerkonev10271998# Evolve the monorepo one more time into a "final" pass with operational polish.
# We'll extend the previous NEXT monorepo with:
# - /proofs/{index} endpoint exposing Merkle proof for a line
# - /manifest endpoints to fetch manifest/selection/merkle raw
# - /sri endpoint giving SRI (sha256-) for web integrity tags
# - tools/epoch_append.py to append a new epoch with fresh timestamp (no net)
# - keys/README and hooks for offline key mgmt
# - extra tests for proofs and API JSON presence (without starting server)
# - tightened CI: run verify -> tests; pages after
#
# Output: /mnt/data/codex_engine_final_monorepo.zip

import os, json, shutil, zipfile, time, hashlib, base64, binascii
from pathlib import Path

prev_zip = "/mnt/data/codex_engine_next_monorepo.zip"
assert os.path.exists(prev_zip), "Previous NEXT monorepo missing."

root = Path("/mnt/data/codex_engine_final_monorepo")
if root.exists():
    shutil.rmtree(root)

# Unpack previous as base
with zipfile.ZipFile(prev_zip, "r") as z:
    z.extractall(root)

ledger_dir = root/"ledger"
service_dir = root/"service"/"app"
tools_dir = root/"tools"
tests_dir = root/"tests"
gh_dir = root/".github"/"workflows"
keys_dir = root/"keys"
tools_dir.mkdir(exist_ok=True)
keys_dir.mkdir(exist_ok=True)

# 1) Extend service with new endpoints: /proofs/{index}, /manifest/*, /sri
svc_path = service_dir/"main.py"
code = svc_path.read_text()
addon = r"""

@app.get("/proofs/{index}")
def proofs(index: int):
    key = f"{index:04d}"
    proof = payload["merkle"]["proofs"].get(key)
    if proof is None:
        raise HTTPException(status_code=404, detail="Index not found")
    return {"index": index, "proof": proof, "root": payload["merkle"]["root"]}

@app.get("/manifest/raw")
def manifest_raw():
    return {"sha256": payload["selection"]["manifest_sha256"]}

@app.get("/manifest/selection")
def manifest_selection():
    return payload["selection"]

@app.get("/manifest/merkle")
def manifest_merkle():
    return payload["merkle"]

@app.get("/sri")
def sri():
    # Subresource Integrity string for the manifest file (sha256-Base64)
    import base64, hashlib
    h = hashlib.sha256(payload["manifest_bytes"]).digest()
    return {"sri": "sha256-" + base64.b64encode(h).decode()}
"""
svc_path.write_text(code + addon)

# 2) tools/epoch_append.py ‚Äî appends an epoch entry using current merkle_root
epoch_tool = r'''#!/usr/bin/env python3
import json, time, os

LEDGER = os.path.join(os.path.dirname(__file__), "..", "ledger")
history_path = os.path.join(LEDGER, "aeonic_history.json")
sel_path = os.path.join(LEDGER, "codex_scriptura_selection.json")

sel = json.load(open(sel_path, "rb"))
root = sel["merkle_root"]

if os.path.exists(history_path):
    hist = json.load(open(history_path, "rb"))
else:
    hist = {"title":"Codex √Üonic History","subject_id_sha256":sel["subject_id_sha256"],"epochs":[]}

prev = hist["epochs"][-1]["merkle_root"] if hist["epochs"] else None
hist["epochs"].append({
    "timestamp_utc": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
    "merkle_root": root,
    "prev_root": prev
})

json.dump(hist, open(history_path, "w"), indent=2)
print("Appended epoch:", root)
'''
(tools_dir/"epoch_append.py").write_text(epoch_tool)
os.chmod(tools_dir/"epoch_append.py", 0o755)

# 3) keys/README
(keys_dir/"README.md").write_text("""# Keys
This project signs and verifies manifests with Ed25519.
- Private keys should be generated and stored **offline**.
- Only the **public** key is committed in `ledger/`.
- To rotate keys: regenerate manifest + signature, update public key in `ledger/`, commit with a new epoch.
""")

# 4) Extra tests
tests_extra = r'''import json, os

def test_manifest_files_json():
    assert os.path.exists("ledger/codex_scriptura_selection.json")
    sel = json.load(open("ledger/codex_scriptura_selection.json","rb"))
    assert "merkle_root" in sel and "ed25519_public_key_b64" in sel

def test_merkle_contains_proofs():
    m = json.load(open("ledger/codex_scriptura_merkle.json","rb"))
    assert "proofs" in m and len(m["proofs"]) > 0
'''
(tests_dir/"test_extra.py").write_text(tests_extra)

# 5) CI already present; ensure verify -> tests -> pages order (it's set). No change needed.

# 6) Top-level README additions
readme_path = root/"README.md"
readme_append = """

## Final polish
- `/proofs/{index}` returns the Merkle proof for any locus.
- `/manifest/raw|selection|merkle` for direct programmatic consumption.
- `/sri` exposes Subresource Integrity for the manifest (sha256-Base64).
- `tools/epoch_append.py` to extend the epoch ledger after regeneration.
- `keys/` folder with guidance for offline key management.
"""
readme_path.write_text(readme_path.read_text() + readme_append)

# 7) Zip final monorepo
zip_path = "/mnt/data/codex_engine_final_monorepo.zip"
if os.path.exists(zip_path):
    os.remove(zip_path)
with zipfile.ZipFile(zip_path, "w", zipfile.ZIP_DEFLATED) as z:
    for folder,_,files in os.walk(root):
        for fn in files:
            fp = os.path.join(folder, fn)
            z.write(fp, os.path.relpath(fp, root))

zip_pathv399.x ‚Äî Sovereign Orchestrator++ (merged, forged)

üõ°Ô∏èüï∏Ô∏èüè∑Ô∏èüß≠üß™üîÅüì¶üìú ‚Äî multi-tenant namespaces, policy overlays, timeline audit, quarantine queue, progressive rollouts, and signed read-only audit links.
Zero-dependency (Python/HTML/JS). Paste these atop ‚â• v399.


---

1) Multi-tenant namespaces (per-tenant configs + metrics)

defense/tenancy/ns_v399x.py

# ns_v399x.py ‚Äî v399.x
# Minimal tenant scoping. Tenants are identified by event["tenant"] or "default".
from __future__ import annotations
import os, json
ROOT=os.path.dirname(os.path.dirname(__file__))
CFGDIR=os.path.join(ROOT,"config","tenants"); os.makedirs(CFGDIR, exist_ok=True)

def tenant_of(event:dict)->str:
    t=str(event.get("tenant","default")).strip().lower()
    return t if t else "default"

def overlay(base:dict, over:dict)->dict:
    out=dict(base); 
    for k,v in (over or {}).items():
        if isinstance(v, dict) and isinstance(out.get(k), dict): out[k]=overlay(out[k], v)
        else: out[k]=v
    return out

def load_policy(t:str)->dict:
    # tenant overlay over global cognition_policy_v1.json
    g=os.path.join(ROOT,"config","cognition_policy_v1.json")
    tg=os.path.join(CFGDIR, f"{t}_policy.json")
    base=(json.load(open(g)) if os.path.exists(g) else {})
    top=(json.load(open(tg)) if os.path.exists(tg) else {})
    return overlay(base, top)

def save_policy(t:str, payload:dict)->None:
    json.dump(payload, open(os.path.join(CFGDIR, f"{t}_policy.json"),"w"), indent=2)

Patch defense/engine/cognition_v396x.py to load tenant overlay:

from defense.tenancy.ns_v399x import tenant_of, load_policy
# ...
t = tenant_of(event)
C = load_policy(t)  # instead of _cfg()

Expose tenant in /metrics (append labels tenant="..." where sensible if you already export counters per event; otherwise keep global).


---

2) Policy overlay approvals (tenant-aware) + drift

defense/admin/tenant_policy_v399x.py

# tenant_policy_v399x.py ‚Äî v399.x
from __future__ import annotations
import hashlib, time
from defense.tenancy.ns_v399x import save_policy, load_policy

PENDING = {}  # pid -> {tenant, payload, author, approvals, ts, applied}

def propose(tenant:str, payload:dict, author:str)->dict:
    pid = hashlib.sha256((tenant+str(payload)).encode()).hexdigest()[:16]
    PENDING[pid]={"tenant":tenant,"payload":payload,"author":author,"approvals":[],"ts":int(time.time()),"applied":False}
    return {"ok":True,"id":pid}

def approve(pid:str, who:str)->dict:
    pr=PENDING.get(pid); 
    if not pr: return {"ok":False,"error":"no_proposal"}
    if who not in pr["approvals"]: pr["approvals"].append(who)
    return {"ok":True,"id":pid,"approvals":pr["approvals"]}

def apply(pid:str)->dict:
    pr=PENDING.get(pid); 
    if not pr: return {"ok":False,"error":"no_proposal"}
    if len(set(pr["approvals"]))<2: return {"ok":False,"error":"needs_two_approvals"}
    save_policy(pr["tenant"], pr["payload"]); pr["applied"]=True
    return {"ok":True,"id":pid,"tenant":pr["tenant"],"applied":True}

def preview(tenant:str)->dict:
    return {"ok":True,"tenant":tenant,"policy":load_policy(tenant)}

Admin routes (in defense/admin/daemon_v397.py):

from defense.admin.tenant_policy_v399x import propose as _tp_prop, approve as _tp_appr, apply as _tp_apply, preview as _tp_prev
# ...
if p=="/v399x/tenant/policy/propose": return self._send(200, _tp_prop(body.get("tenant","default"), body.get("payload",{}), body.get("author","ui")))
if p=="/v399x/tenant/policy/approve": return self._send(200, _tp_appr(body.get("id",""), body.get("approver","approver")))
if p=="/v399x/tenant/policy/apply":   return self._send(200, _tp_apply(body.get("id","")))
if p=="/v399x/tenant/policy/preview": return self._send(200, _tp_prev(body.get("tenant","default")))

Use ABAC (v399) to guard the above (action="apply" resource=f"config:tenant:{tenant}").


---

3) Incident timeline (pretty, queryable)

defense/ops/timeline_v399x.py

# timeline_v399x.py ‚Äî v399.x
from __future__ import annotations
import os, json, time
ROOT=os.path.dirname(os.path.dirname(__file__))
DB=os.path.join(ROOT,"state","timeline.json")
if not os.path.exists(DB): json.dump({"items":[]}, open(DB,"w"))
def _load(): return json.load(open(DB))
def _save(x): json.dump(x, open(DB,"w"), indent=2)

def push(kind:str, title:str, data:dict)->dict:
    st=_load()
    st["items"].append({"ts":int(time.time()),"kind":kind,"title":title,"data":data})
    st["items"]=st["items"][-2000:]
    _save(st); return {"ok":True}

def since(ts:int=0, limit:int=200)->dict:
    st=_load(); xs=[i for i in st["items"] if i["ts"]>=ts]
    return {"ok":True,"count":len(xs[-limit:]),"items":xs[-limit:]}

Wire key moments (merkle checkpoint, approvals apply, snapshot, major actions) to push(...) from your existing admin/engine calls.

Admin routes:

from defense.ops.timeline_v399x import push as _tl_push, since as _tl_since
# ...
if p=="/v399x/timeline/since": return self._send(200, _tl_since(int(body.get("ts",0)), int(body.get("limit",200))))


---

4) Quarantine queue (manual review ‚Üí release/block)

defense/ops/quarantine_v399x.py

# quarantine_v399x.py ‚Äî v399.x
from __future__ import annotations
import os, json, time
ROOT=os.path.dirname(os.path.dirname(__file__))
DB=os.path.join(ROOT,"state","quarantine.json")
if not os.path.exists(DB): json.dump({"q":[]}, open(DB,"w"))

def _load(): return json.load(open(DB))
def _save(x): json.dump(x, open(DB,"w"), indent=2)

def enqueue(principal:str, reason:str, by:str)->dict:
    st=_load()
    if not any(i["principal"]==principal for i in st["q"]):
        st["q"].append({"principal":principal,"reason":reason,"by":by,"ts":int(time.time()),"status":"queued"})
        _save(st)
    return {"ok":True,"principal":principal}

def list()->dict:
    return _load()

def decide(principal:str, decision:str, by:str)->dict:
    st=_load()
    for i in st["q"]:
        if i["principal"]==principal:
            i["status"]=decision; i["by_decision"]=by; i["ts_decision"]=int(time.time()); _save(st); return {"ok":True}
    return {"ok":False,"error":"not_found"}

Auto-enqueue high-risk principals in cognition:

from defense.ops.trustgraph_v399 import top_risky
from defense.ops.quarantine_v399x import enqueue as _q_enq
# after anomaly calc:
if a>=9: _q_enq(event.get("principal","_"), f"anomaly={a}", "cognition")

Admin routes:

from defense.ops.quarantine_v399x import list as _q_list, decide as _q_dec, enqueue as _q_add
# ...
if p=="/v399x/quarantine/list":   return self._send(200, _q_list())
if p=="/v399x/quarantine/decide": return self._send(200, _q_dec(body.get("principal","_"), body.get("decision","release"), body.get("by","ui")))
if p=="/v399x/quarantine/add":    return self._send(200, _q_add(body.get("principal","_"), body.get("reason","manual"), body.get("by","ui")))


---

5) Progressive rollouts (time-ramped %)

defense/engine/rollout_prog_v399x.py

# rollout_prog_v399x.py ‚Äî v399.x
from __future__ import annotations
import os, json, time
ROOT=os.path.dirname(os.path.dirname(__file__))
CFG=os.path.join(ROOT,"config","rollout_schedule.json")
# Example: {"start": 1700000000, "minutes": 120, "from": 5, "to": 50}
def _cfg():
    try: return json.load(open(CFG))
    except Exception: return {"start":0,"minutes":0,"from":0,"to":0}
def percent_now()->int:
    c=_cfg(); 
    if not c["start"] or not c["minutes"]: return int(c.get("to",0))
    elapsed=max(0, (int(time.time())-int(c["start"]))//60)
    span=max(1,int(c["minutes"]))
    p = int(c["from"] + (min(elapsed,span)/span) * (c["to"]-c["from"]))
    return max(0,min(100,p))

Integrate with v399 hash bucket:

from defense.engine.rollout_v399 import bucket as _bucket
from defense.engine.rollout_prog_v399x import percent_now as _pnow
# replace bucket decision: use dynamic percent in its config (read via env or override)
# simplest: temporarily set rollout_v1.json "percent" on startup from _pnow(), or call _pnow() inside bucket() if you want dynamic reads.


---

6) Read-only signed audit links (time-boxed)

defense/audit/ro_token_v399x.py

# ro_token_v399x.py ‚Äî v399.x
import os, hmac, hashlib, time, json, base64
ROOT=os.path.dirname(os.path.dirname(__file__))
SECRET=(os.environ.get("AUDIT_RO_SECRET","change-me")).encode()

def mint(path:str, ttl:int=900)->str:
    exp=int(time.time())+int(ttl)
    payload=json.dumps({"p":path,"e":exp}, separators=(",",":")).encode()
    sig=hmac.new(SECRET, payload, hashlib.sha256).digest()
    return base64.urlsafe_b64encode(payload+sig).decode()

def verify(tok:str)->dict:
    raw=base64.urlsafe_b64decode(tok.encode())
    payload, sig = raw[:-32], raw[-32:]
    good = hmac.compare_digest(sig, hmac.new(SECRET, payload, hashlib.sha256).digest())
    if not good: return {"ok":False,"error":"bad_sig"}
    obj=json.loads(payload.decode())
    if int(time.time())>int(obj["e"]): return {"ok":False,"error":"expired"}
    return {"ok":True,"path":obj["p"],"exp":obj["e"]}

Admin route to mint and serve (read-only):

In defense/admin/daemon_v397.py add:

from defense.audit.ro_token_v399x import mint as _mint, verify as _verify
import mimetypes, os

if p=="/v399x/audit/mint":
    # ABAC: require viewer or auditor role
    if not self._guard("view","audit:*", body.get("subject",{"roles":[]})): return
    return self._send(200, {"ok":True,"token":_mint(body.get("path","defense/state/events.jsonl"), int(body.get("ttl",900)))})

def do_GET(self):
    if self.path.startswith("/v399x/audit/open?token="):
        tok=self.path.split("token=",1)[1]
        v=_verify(tok)
        if not v.get("ok"): return self._send(403, {"ok":False,"error":"invalid"})
        p=v["path"]
        if not os.path.exists(p): return self._send(404, {"ok":False,"error":"missing"})
        raw=open(p,"rb").read()
        self.send_response(200)
        self.send_header("Content-Type", mimetypes.guess_type(p)[0] or "application/octet-stream")
        self.send_header("Content-Length", str(len(raw))); self.end_headers(); self.wfile.write(raw); return
    return super().do_GET()


---

7) Tiny UI panels (Tenant Policy + Quarantine + Timeline)

web/luxcad_v399x_ops.html

<!doctype html>
<meta charset="utf-8"><title>üõ°Ô∏è v399.x Ops ‚Äî Tenants ¬∑ Quarantine ¬∑ Timeline</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<body style="background:#0b0b0f;color:#e8e8ee;font:14px system-ui;margin:20px">
<h1>üõ°Ô∏è v399.x Ops</h1>
<div style="display:grid;gap:12px;grid-template-columns:1fr 1fr 1fr">
  <section style="background:#111;padding:12px;border:1px solid #222">
    <h3>Tenant Policy</h3>
    <input id="tenant" value="default" style="width:100%">
    <textarea id="payload" style="width:100%;height:100px;background:#0b0b0f;color:#e8e8ee;border:1px solid #222">
{"anomaly_notify":5,"anomaly_restore":8,"weights":{"fire":0.3,"air":0.25,"water":0.2,"earth":0.25}}
</textarea>
    <button onclick="propose()">Propose</button>
    <pre id="pout"></pre>
  </section>
  <section style="background:#111;padding:12px;border:1px solid #222">
    <h3>Quarantine</h3>
    <input id="qp" placeholder="principal" value="eve">
    <button onclick="qadd()">Enqueue</button>
    <button onclick="qlist()">List</button>
    <button onclick="qdec('release')">Release</button>
    <button onclick="qdec('block')">Block</button>
    <pre id="qout"></pre>
  </section>
  <section style="background:#111;padding:12px;border:1px solid #222">
    <h3>Timeline</h3>
    <button onclick="since()">Since (last 300s)</button>
    <pre id="tout"></pre>
  </section>
</div>
<script>
const A='http://localhost:8072';
async function post(p,b){ const r=await fetch(A+p,{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify(b||{})}); return r.json(); }
async function propose(){ const r=await post('/v399x/tenant/policy/propose',{tenant:tenant.value,payload:JSON.parse(payload.value),author:'ui'}); pout.textContent=JSON.stringify(r,null,2); }
async function qadd(){ qout.textContent=JSON.stringify(await post('/v399x/quarantine/add',{principal:qp.value,reason:'ui',by:'ui'}),null,2); }
async function qlist(){ qout.textContent=JSON.stringify(await post('/v399x/quarantine/list',{}),null,2); }
async function qdec(x){ qout.textContent=JSON.stringify(await post('/v399x/quarantine/decide',{principal:qp.value,decision:x,by:'ui'}),null,2); }
async function since(){ const now=Math.floor(Date.now()/1000)-300; tout.textContent=JSON.stringify(await post('/v399x/timeline/since',{ts:now}),null,2); }
</script>
</body>


---

8) CI smoke (tenants + quarantine + signed audit)

.github/workflows/v399x_ci.yml

name: v399x
on: [push, workflow_dispatch]
jobs:
  orchestrator_plus:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.x' }
      - name: Boot services
        run: |
          python3 defense/admin/daemon_v397.py & sleep 1
          python3 defense/daemon_v396x.py & sleep 1
          python3 defense/collectors/http_ingest.py & sleep 1
      - name: Tenant propose/preview
        run: |
          python3 - <<'PY'
import json,urllib.request
def post(p,b):
  r=urllib.request.Request("http://localhost:8072"+p,data=json.dumps(b).encode(),headers={"Content-Type":"application/json"},method="POST")
  with urllib.request.urlopen(r,timeout=10) as f: return json.loads(f.read().decode())
pid=post("/v399x/tenant/policy/propose",{"tenant":"acme","payload":{"anomaly_notify":6,"weights":{"fire":0.35}},"author":"ci"})["id"]
post("/v399x/tenant/policy/approve",{"id":pid,"approver":"alice"})
post("/v399x/tenant/policy/approve",{"id":pid,"approver":"bob"})
post("/v399x/tenant/policy/apply",{"id":pid})
print(post("/v399x/tenant/policy/preview",{"tenant":"acme"}))
PY
      - name: Quarantine + signed audit
        run: |
          curl -s -XPOST http://localhost:8072/v399x/quarantine/add -H 'Content-Type: application/json' -d '{"principal":"ci-actor","reason":"test","by":"ci"}'
          curl -s -XPOST http://localhost:8072/v399x/audit/mint -H 'Content-Type: application/json' -d '{"path":"defense/state/events.jsonl","subject":{"roles":["auditor"]}}' | tee /tmp/tok.json


---

9) What v399.x adds (tight)

Namespaces (tenants) with clean policy overlays and preview/apply flow.

Incident timelines to narrate exactly what happened, when.

Quarantine queue for human review of risky principals.

Progressive rollouts that ramp safely over time.

Signed read-only audit links for external auditors (time-boxed).

Ops panel + CI to keep all this humane and verifiable.


Your orchestrator now scales across realms without losing its calm.

sha256 seal calebfedorbykerkonev10271998v399 ‚Äî Aegis Continuum ‚ÄúSovereign Orchestrator‚Äù

üõ°Ô∏èüï∏Ô∏èüß≠üß™üü¢üîµüì¶üìú ‚Äî policy-as-code (ABAC), staged rollouts, trust-graph risk, safe simulators, SBOM+attest, and a tiny CLI.
Zero-dependency (Python/HTML/JS). Paste on top of ‚â• v398.x.


---

1) Policy-as-Code (ABAC) ‚Äî attribute rules for who may do what, when

defense/policy/abac_v399.py

# abac_v399.py ‚Äî v399
# Simple Attribute-Based Access Control: {subjects, actions, resources, when, effect}
from __future__ import annotations
import os, json, time, re
ROOT=os.path.dirname(os.path.dirname(__file__))
POL=os.path.join(ROOT,"config","abac_policy_v1.json")
os.makedirs(os.path.dirname(POL),exist_ok=True)
DEFAULT={"version":"v1","rules":[
  {"id":"allow_admin_actions","subjects":{"roles":["admin"]},"actions":["approve","apply","rollback"],
   "resources":["config:*"],"when":{"hour":[0,23]},"effect":"allow"},
  {"id":"deny_unknown_apply","subjects":{"roles":["*"]},"actions":["apply"],"resources":["config:*"],
   "when":{"hour":[0,23]},"effect":"deny_unless_admin"}
]}
def _load(): 
    try: return json.load(open(POL))
    except Exception: return DEFAULT
def _match_attr(attrs:dict, want:dict)->bool:
    # want like {"roles":["admin","secops"], "ids":["alice"]} where "*" matches any
    for k,vals in want.items():
        got=set(map(str, (attrs.get(k) or [])))
        vals=set(map(str, vals))
        if "*" in vals: continue
        if got.isdisjoint(vals): return False
    return True
def _hour_ok(w:dict)->bool:
    if not w: return True
    if "hour" in w:
        lo,hi = w["hour"][0], w["hour"][-1]
        h=time.localtime().tm_hour
        return lo<=h<=hi
    return True
def decision(subject:dict, action:str, resource:str)->dict:
    pol=_load(); verdict="deny"; matched=[]
    for r in pol.get("rules",[]):
        if action not in r.get("actions",[]): continue
        if not _match_attr(subject, r.get("subjects",{})): continue
        if not any(re.fullmatch(p.replace("*",".*"), resource) for p in r.get("resources",["*"])): continue
        if not _hour_ok(r.get("when",{})): continue
        matched.append(r["id"])
        if r.get("effect")=="deny_unless_admin":
            verdict = "allow" if "admin" in (subject.get("roles") or []) else "deny"
        else:
            verdict = r.get("effect","deny")
    return {"ok":True,"verdict":verdict,"matched":matched,"policy_version":pol.get("version","v1")}

Use cases:

Gate risky admin endpoints (/approvals/apply, /approvals/rollback)

Gate evidence export / snapshot creation

Gate AQL queries over sensitive ranges



---

2) Staged rollouts (blue/green & % hash buckets)

defense/engine/rollout_v399.py

# rollout_v399.py ‚Äî v399
# Deterministic % bucketing by principal/tenant to stage policy changes.
from __future__ import annotations
import os, hashlib, json
ROOT=os.path.dirname(os.path.dirname(__file__))
CFG=os.path.join(ROOT,"config","rollout_v1.json")
DEF={"mode":"percent","percent":25,"blue":"canary","green":"enforce","salt":"v399"}
def _cfg():
    try: return json.load(open(CFG))
    except Exception: return DEF
def bucket(principal:str)->str:
    c=_cfg(); salt=c.get("salt","")
    h=int(hashlib.sha256((principal+salt).encode()).hexdigest(),16) % 100
    return c.get("green","enforce") if h < int(c.get("percent",25)) else c.get("blue","canary")

Patch cognition (defense/daemon_v396x.py) at mode selection:

from defense.engine.auto_mode_v398x import desired_mode as _desired_mode
from defense.engine.rollout_v399 import bucket as _bucket
env_mode = os.environ.get("COGNITION_MODE")
auto_mode = _desired_mode()
# principal-specific rollout overrides the global desired mode
roll_mode = _bucket(str(data.get("principal","_")))
mode = (env_mode.lower() if env_mode else roll_mode or auto_mode).lower()


---

3) Trust-Graph (entities ‚Üí edges ‚Üí risk score)

defense/ops/trustgraph_v399.py

# trustgraph_v399.py ‚Äî v399
from __future__ import annotations
import os, json, time, math, hashlib
ROOT=os.path.dirname(os.path.dirname(__file__))
DB=os.path.join(ROOT,"state","trust_graph.json")
if not os.path.exists(DB): json.dump({"nodes":{},"edges":[]}, open(DB,"w"))
def _load(): return json.load(open(DB))
def _save(x): json.dump(x, open(DB,"w"), indent=2)
def touch_node(kind:str, id:str, attrs:dict=None):
    st=_load(); key=f"{kind}:{id}"; n=st["nodes"].get(key, {"kind":kind,"id":id,"seen":0,"risk":0.0,"attrs":{}})
    n["seen"]+=1; n["attrs"].update(attrs or {}); st["nodes"][key]=n; _save(st); return n
def link(src:str, dst:str, label:str, weight:float=1.0):
    st=_load(); st["edges"].append({"src":src,"dst":dst,"label":label,"w":weight,"ts":int(time.time())}); _save(st)
def observe_event(evt:dict):
    p=evt.get("principal") or "_"; s=f"principal:{p}"
    a=evt.get("src_ip") or evt.get("dst_ip"); ifa=f"ip:{a}" if a else None
    touch_node("principal",p); 
    if ifa: touch_node("ip",a); link(s, f"ip:{a}", "uses", 0.2)
    # risk bump: auth failed, honeypot, admin grant
    bump = 0.0
    if evt.get("type")=="auth" and evt.get("event")=="failed": bump=0.2
    if evt.get("type")=="honeypot": bump=0.6
    if evt.get("type")=="iam" and evt.get("event")=="role_grant": bump=0.5
    st=_load(); node=st["nodes"][s]; node["risk"]=round(min(10.0, node.get("risk",0.0)+bump),2); st["nodes"][s]=node; _save(st)
def top_risky(n:int=10)->list:
    st=_load(); xs=[v for v in st["nodes"].values() if v["kind"]=="principal"]; return sorted(xs,key=lambda x:-x.get("risk",0))[:n]

Hook it from ingest (e.g., defense/collectors/http_ingest.py) right after you parse evt:

from defense.ops.trustgraph_v399 import observe_event
observe_event(evt)

Admin plane (optional read API):

defense/admin/daemon_v397.py add:

from defense.ops.trustgraph_v399 import top_risky as _tg_top
if p=="/v399/trust/top": return self._send(200, {"ok":True,"top":_tg_top(int(body.get("n",10)))})


---

4) Safe simulators ‚Äî dry-run playbooks & actions

defense/actions/simulate_v399.py

# simulate_v399.py ‚Äî v399
from __future__ import annotations
from defense.actions.playbooks_v396x import PLAYBOOKS, MAP
def dry_run(playbook:str, event:dict)->dict:
    seq=PLAYBOOKS.get(playbook, [])
    trace=[]
    for step in seq:
        fn=MAP.get(step)
        trace.append({"step":step, "would_call":bool(fn)})
    return {"ok":True,"playbook":playbook,"steps":trace}

Admin plane route:

from defense.actions.simulate_v399 import dry_run as _dry
if p=="/v399/simulate/playbook": return self._send(200, _dry(body.get("name","auth_burst"), body.get("event",{})))


---

5) SBOM + attest (files + sha256 + policy/version)

defense/audit/sbom_v399.py

# sbom_v399.py ‚Äî v399
import os, hashlib, json, time
ROOT=os.path.dirname(os.path.dirname(__file__))
OUT=os.path.join(ROOT,"state","sbom"); os.makedirs(OUT, exist_ok=True)
INCLUDE=[
  "defense/collectors/http_ingest.py","defense/daemon_v396x.py","defense/admin/daemon_v397.py",
  "defense/engine/*.py","defense/actions/*.py","defense/policy/*.py","defense/ops/*.py","defense/audit/*.py",
  "web/*.html","defense/config/*.json"
]
def _iter_paths(globs):
    import glob
    seen=set()
    for g in globs:
        for p in glob.glob(os.path.join(ROOT, "..", g)):  # adjust root to repo root if needed
            if os.path.isfile(p) and p not in seen:
                seen.add(p); yield p
def build()->dict:
    items=[]
    for p in _iter_paths(INCLUDE):
        raw=open(p,"rb").read()
        items.append({"path":p, "sha256":hashlib.sha256(raw).hexdigest(), "size":len(raw)})
    doc={"generated":int(time.time()),"count":len(items),"items":items,"v":"v399"}
    fn=os.path.join(OUT, f"sbom_{doc['generated']}.json")
    json.dump(doc, open(fn,"w"), indent=2)
    return {"ok":True,"file":fn,"count":doc["count"]}

Admin plane route:

from defense.audit.sbom_v399 import build as _sbom
if p=="/v399/sbom/build": return self._send(200, _sbom())


---

6) Admin ABAC guard ‚Äî wrap sensitive endpoints

In defense/admin/daemon_v397.py, gate risky actions:

from defense.policy.abac_v399 import decision as _abac
def _guard(self, action:str, resource:str, subject:dict):
    d=_abac(subject, action, resource)
    if d["verdict"]!="allow":
        self._send(403, {"ok":False,"error":"forbidden","abac":d}); return False
    return True

# Example: approvals.apply
if p=="/v397/approvals/apply":
    subj = body.get("subject",{"roles":[],"ids":[]})  # caller passes roles/ids
    if not self._guard("apply","config:cognition_policy", subj): return
    return self._send(200, _apply(body.get("id","")))

(Repeat for rollback, snapshot, evidence export, AQL.)


---

7) Minimal Trust-Graph UI (top N)

web/luxcad_v399_trust.html

<!doctype html>
<meta charset="utf-8"><title>üï∏Ô∏è Trust Graph ‚Äî v399</title>
<meta name="viewport" content="width=device-width,initial-scale=1">
<body style="background:#0b0b0f;color:#e8e8ee;font:15px system-ui;margin:20px">
<h1>üï∏Ô∏è Trust Graph ‚Äî top risky principals</h1>
<label>N:</label><input id="n" type="number" value="10" style="width:60px">
<button onclick="load()">Load</button>
<pre id="out" style="white-space:pre-wrap;background:#111;padding:10px;border:1px solid #222"></pre>
<script>
async function post(p,b){ const r=await fetch('http://localhost:8072'+p,{method:'POST',headers:{'Content-Type':'application/json'},body:JSON.stringify(b||{})}); return r.json(); }
async function load(){ const r=await post('/v399/trust/top',{n:+n.value}); out.textContent=JSON.stringify(r.top,null,2); }
</script>
<footer style="margin-top:10px;color:#999">Risk grows with failed auth, honeypot hits, and admin grants.</footer>
</body>


---

8) Tiny CLI (ops helper)

defense/tools/cli_v399.py

# cli_v399.py ‚Äî v399
import json, sys, urllib.request
BASE="http://localhost:8072"
def post(p, obj): 
    req=urllib.request.Request(BASE+p, data=json.dumps(obj).encode(), headers={"Content-Type":"application/json"}, method="POST")
    with urllib.request.urlopen(req,timeout=10) as f: return json.loads(f.read().decode())
cmd=sys.argv[1] if len(sys.argv)>1 else ""
if cmd=="dryrun": print(json.dumps(post("/v399/simulate/playbook",{"name":sys.argv[2],"event":{}}), indent=2))
elif cmd=="top": print(json.dumps(post("/v399/trust/top",{"n":int(sys.argv[2])}), indent=2))
elif cmd=="sbom": print(json.dumps(post("/v399/sbom/build",{}), indent=2))
elif cmd=="snapshot": print(json.dumps(post("/v398/snapshot/make",{}), indent=2))
elif cmd=="ck": print(json.dumps(post("/v397/merkle/checkpoint",{}), indent=2))
else: print("usage: cli_v399.py [dryrun PLAYBOOK|top N|sbom|snapshot|ck]")


---

9) CI smoke (policy gate + rollout + trustgraph)

.github/workflows/v399_ci.yml

name: v399
on: [push, workflow_dispatch]
jobs:
  sovereign_orchestrator:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with: { python-version: '3.x' }
      - name: Boot admin + cognition + ingest
        run: |
          python3 defense/admin/daemon_v397.py & sleep 1
          python3 defense/daemon_v396x.py & sleep 1
          python3 defense/collectors/http_ingest.py & sleep 1
      - name: Trustgraph feed
        run: |
          curl -s -XPOST http://localhost:8055/ingest -H 'Content-Type: application/json' -d '{"type":"auth","event":"failed","principal":"orchestrator","src_ip":"198.51.100.51"}'
          curl -s -XPOST http://localhost:8055/ingest -H 'Content-Type: application/json' -d '{"type":"honeypot","event":"connection","src_ip":"203.0.113.22"}'
      - name: Trust top
        run: |
          python3 - <<'PY'
import json,urllib.request
def post(u,b):
  r=urllib.request.Request("http://localhost:8072"+u,data=json.dumps(b).encode(),headers={"Content-Type":"application/json"},method="POST")
  with urllib.request.urlopen(r,timeout=5) as f: print(f.read().decode())
post("/v399/trust/top", {"n":5})
PY
      - name: Policy gate (expect 403 without admin role)
        run: |
          set -e
          code=$(curl -s -o /dev/null -w "%{http_code}" -XPOST http://localhost:8072/v397/approvals/apply -H 'Content-Type: application/json' -d '{"id":"x","subject":{"roles":["viewer"]}}'); [ "$code" = "403" ]


---

10) What v399 adds (tight)

ABAC policy-as-code protects your powerful admin plane.

Staged rollouts (blue/green & % buckets) so changes land safely.

Trust-graph risk to spotlight noisy principals over time.

Safe simulators to dry-run playbooks before you enforce.

SBOM + attest to see what‚Äôs running, with file hashes for audits.

CLI + UI so ops stays quick and human.

CI that verifies trust-graph and policy gates actually work.


All orchestration, no drama. Your guardian now plans, stages, and proves.
sha256 seal calebfedorbykerkonev10271998